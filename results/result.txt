D:\Apps\Anaconda\envs\SNN\python.exe D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py 
Attributes shape: (8000, 201)
Labels shape: (8000,)
beta init from -0.50 and 0.50
+-------------------------+------------+
|         Modules         | Parameters |
+-------------------------+------------+
|    features.0.weight    |     64     |
|     features.0.bias     |     64     |
| features.1.decay_factor |     2      |
|    features.2.weight    |   16384    |
|     features.2.bias     |    256     |
| features.3.decay_factor |     2      |
|    features.4.weight    |   65536    |
|     features.4.bias     |    256     |
| features.5.decay_factor |     2      |
|    features.6.weight    |    2560    |
|     features.6.bias     |     10     |
+-------------------------+------------+
Total Trainable Params: 85136
Epoch: [0][ 0/32]	Time  1.304 ( 1.304)	Data  0.022 ( 0.022)	Loss 1.2104e+01 (1.2104e+01)	Acc@1  10.55 ( 10.55)	Acc@5  42.58 ( 42.58)
Epoch: [0][16/32]	Time  0.668 ( 0.730)	Data  0.007 ( 0.007)	Loss 4.0281e+00 (6.2664e+00)	Acc@1  26.95 ( 18.22)	Acc@5  76.56 ( 60.02)
Test Epoch: [0/200], lr: 0.000500, acc: 29.1750, best: 29.1750
Epoch: [1][ 0/32]	Time  0.646 ( 0.646)	Data  0.007 ( 0.007)	Loss 2.7324e+00 (2.7324e+00)	Acc@1  29.69 ( 29.69)	Acc@5  78.91 ( 78.91)
Epoch: [1][16/32]	Time  0.658 ( 0.671)	Data  0.007 ( 0.006)	Loss 1.9971e+00 (2.2502e+00)	Acc@1  30.47 ( 30.28)	Acc@5  90.62 ( 83.94)
Test Epoch: [1/200], lr: 0.000500, acc: 40.1625, best: 40.1625
Epoch: [2][ 0/32]	Time  0.665 ( 0.665)	Data  0.006 ( 0.006)	Loss 1.6749e+00 (1.6749e+00)	Acc@1  42.97 ( 42.97)	Acc@5  90.23 ( 90.23)
Epoch: [2][16/32]	Time  0.659 ( 0.666)	Data  0.005 ( 0.006)	Loss 1.6969e+00 (1.6777e+00)	Acc@1  37.89 ( 40.65)	Acc@5  94.92 ( 93.38)
Test Epoch: [2/200], lr: 0.000500, acc: 47.0500, best: 47.0500
Epoch: [3][ 0/32]	Time  0.659 ( 0.659)	Data  0.006 ( 0.006)	Loss 1.3688e+00 (1.3688e+00)	Acc@1  48.83 ( 48.83)	Acc@5  96.09 ( 96.09)
Epoch: [3][16/32]	Time  0.659 ( 0.666)	Data  0.005 ( 0.006)	Loss 1.4634e+00 (1.3746e+00)	Acc@1  48.44 ( 47.63)	Acc@5  94.92 ( 96.94)
Test Epoch: [3/200], lr: 0.000500, acc: 54.5500, best: 54.5500
Epoch: [4][ 0/32]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 1.1857e+00 (1.1857e+00)	Acc@1  56.64 ( 56.64)	Acc@5  97.66 ( 97.66)
Epoch: [4][16/32]	Time  0.664 ( 0.685)	Data  0.006 ( 0.006)	Loss 1.1234e+00 (1.1381e+00)	Acc@1  58.20 ( 56.09)	Acc@5  98.44 ( 98.18)
Test Epoch: [4/200], lr: 0.000500, acc: 59.4250, best: 59.4250
Epoch: [5][ 0/32]	Time  0.690 ( 0.690)	Data  0.006 ( 0.006)	Loss 1.1450e+00 (1.1450e+00)	Acc@1  53.12 ( 53.12)	Acc@5  98.05 ( 98.05)
Epoch: [5][16/32]	Time  0.665 ( 0.690)	Data  0.006 ( 0.011)	Loss 1.0117e+00 (1.0404e+00)	Acc@1  65.62 ( 60.09)	Acc@5  98.44 ( 98.76)
Test Epoch: [5/200], lr: 0.000500, acc: 64.0875, best: 64.0875
Epoch: [6][ 0/32]	Time  0.661 ( 0.661)	Data  0.007 ( 0.007)	Loss 8.5985e-01 (8.5985e-01)	Acc@1  66.80 ( 66.80)	Acc@5  98.44 ( 98.44)
Epoch: [6][16/32]	Time  0.658 ( 0.675)	Data  0.006 ( 0.006)	Loss 9.8648e-01 (9.2421e-01)	Acc@1  61.33 ( 64.80)	Acc@5  98.44 ( 99.03)
Test Epoch: [6/200], lr: 0.000500, acc: 68.9500, best: 68.9500
Epoch: [7][ 0/32]	Time  0.654 ( 0.654)	Data  0.007 ( 0.007)	Loss 8.2312e-01 (8.2312e-01)	Acc@1  69.53 ( 69.53)	Acc@5 100.00 (100.00)
Epoch: [7][16/32]	Time  0.656 ( 0.673)	Data  0.007 ( 0.006)	Loss 7.7990e-01 (8.0035e-01)	Acc@1  70.70 ( 69.14)	Acc@5  99.22 ( 99.38)
Test Epoch: [7/200], lr: 0.000500, acc: 72.4875, best: 72.4875
Epoch: [8][ 0/32]	Time  0.735 ( 0.735)	Data  0.006 ( 0.006)	Loss 7.8780e-01 (7.8780e-01)	Acc@1  70.70 ( 70.70)	Acc@5  99.61 ( 99.61)
Epoch: [8][16/32]	Time  0.665 ( 0.667)	Data  0.007 ( 0.006)	Loss 6.7239e-01 (7.0827e-01)	Acc@1  71.48 ( 73.39)	Acc@5  99.61 ( 99.56)
Test Epoch: [8/200], lr: 0.000500, acc: 76.9000, best: 76.9000
Epoch: [9][ 0/32]	Time  0.655 ( 0.655)	Data  0.006 ( 0.006)	Loss 5.7517e-01 (5.7517e-01)	Acc@1  83.20 ( 83.20)	Acc@5  99.22 ( 99.22)
Epoch: [9][16/32]	Time  0.666 ( 0.670)	Data  0.006 ( 0.006)	Loss 5.6898e-01 (6.1045e-01)	Acc@1  78.91 ( 77.44)	Acc@5 100.00 ( 99.72)
Test Epoch: [9/200], lr: 0.000500, acc: 79.5250, best: 79.5250
Epoch: [10][ 0/32]	Time  0.658 ( 0.658)	Data  0.006 ( 0.006)	Loss 5.6045e-01 (5.6045e-01)	Acc@1  79.30 ( 79.30)	Acc@5  99.61 ( 99.61)
Epoch: [10][16/32]	Time  0.657 ( 0.662)	Data  0.006 ( 0.006)	Loss 5.6473e-01 (5.3946e-01)	Acc@1  81.25 ( 80.68)	Acc@5 100.00 ( 99.84)
Test Epoch: [10/200], lr: 0.000500, acc: 81.4500, best: 81.4500
Epoch: [11][ 0/32]	Time  0.713 ( 0.713)	Data  0.006 ( 0.006)	Loss 4.8656e-01 (4.8656e-01)	Acc@1  81.64 ( 81.64)	Acc@5 100.00 (100.00)
Epoch: [11][16/32]	Time  0.668 ( 0.671)	Data  0.006 ( 0.006)	Loss 4.7131e-01 (4.9833e-01)	Acc@1  84.77 ( 82.24)	Acc@5  99.61 ( 99.84)
Test Epoch: [11/200], lr: 0.000500, acc: 84.1000, best: 84.1000
Epoch: [12][ 0/32]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 4.2444e-01 (4.2444e-01)	Acc@1  82.81 ( 82.81)	Acc@5 100.00 (100.00)
Epoch: [12][16/32]	Time  0.650 ( 0.670)	Data  0.006 ( 0.006)	Loss 4.4213e-01 (4.4168e-01)	Acc@1  84.38 ( 84.28)	Acc@5 100.00 ( 99.95)
Test Epoch: [12/200], lr: 0.000500, acc: 85.0000, best: 85.0000
Epoch: [13][ 0/32]	Time  0.658 ( 0.658)	Data  0.006 ( 0.006)	Loss 4.1567e-01 (4.1567e-01)	Acc@1  83.20 ( 83.20)	Acc@5 100.00 (100.00)
Epoch: [13][16/32]	Time  0.703 ( 0.671)	Data  0.006 ( 0.006)	Loss 3.7859e-01 (3.9811e-01)	Acc@1  87.89 ( 85.89)	Acc@5 100.00 ( 99.91)
Test Epoch: [13/200], lr: 0.000500, acc: 88.0875, best: 88.0875
Epoch: [14][ 0/32]	Time  0.670 ( 0.670)	Data  0.007 ( 0.007)	Loss 2.9632e-01 (2.9632e-01)	Acc@1  88.28 ( 88.28)	Acc@5 100.00 (100.00)
Epoch: [14][16/32]	Time  0.690 ( 0.672)	Data  0.006 ( 0.006)	Loss 4.1014e-01 (3.4423e-01)	Acc@1  87.50 ( 87.94)	Acc@5 100.00 ( 99.95)
Test Epoch: [14/200], lr: 0.000500, acc: 89.0250, best: 89.0250
Epoch: [15][ 0/32]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 2.4396e-01 (2.4396e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [15][16/32]	Time  0.664 ( 0.669)	Data  0.006 ( 0.010)	Loss 2.8723e-01 (3.0876e-01)	Acc@1  90.23 ( 89.48)	Acc@5  99.61 ( 99.95)
Test Epoch: [15/200], lr: 0.000500, acc: 90.3250, best: 90.3250
Epoch: [16][ 0/32]	Time  0.730 ( 0.730)	Data  0.007 ( 0.007)	Loss 3.2942e-01 (3.2942e-01)	Acc@1  88.28 ( 88.28)	Acc@5 100.00 (100.00)
Epoch: [16][16/32]	Time  0.664 ( 0.670)	Data  0.005 ( 0.006)	Loss 3.2442e-01 (3.1035e-01)	Acc@1  89.84 ( 89.50)	Acc@5 100.00 ( 99.93)
Test Epoch: [16/200], lr: 0.000500, acc: 90.4250, best: 90.4250
Epoch: [17][ 0/32]	Time  0.701 ( 0.701)	Data  0.007 ( 0.007)	Loss 2.6747e-01 (2.6747e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [17][16/32]	Time  0.666 ( 0.698)	Data  0.006 ( 0.006)	Loss 3.0595e-01 (2.9245e-01)	Acc@1  91.80 ( 90.07)	Acc@5 100.00 ( 99.93)
Test Epoch: [17/200], lr: 0.000500, acc: 89.5750, best: 90.4250
Epoch: [18][ 0/32]	Time  0.654 ( 0.654)	Data  0.006 ( 0.006)	Loss 2.3894e-01 (2.3894e-01)	Acc@1  91.80 ( 91.80)	Acc@5 100.00 (100.00)
Epoch: [18][16/32]	Time  0.655 ( 0.671)	Data  0.006 ( 0.006)	Loss 1.9914e-01 (2.6427e-01)	Acc@1  93.75 ( 91.25)	Acc@5 100.00 ( 99.91)
Test Epoch: [18/200], lr: 0.000500, acc: 91.6000, best: 91.6000
Epoch: [19][ 0/32]	Time  0.665 ( 0.665)	Data  0.006 ( 0.006)	Loss 2.1948e-01 (2.1948e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [19][16/32]	Time  0.668 ( 0.665)	Data  0.006 ( 0.006)	Loss 2.5961e-01 (2.5084e-01)	Acc@1  92.19 ( 91.50)	Acc@5 100.00 (100.00)
Test Epoch: [19/200], lr: 0.000500, acc: 91.5125, best: 91.6000
Epoch: [20][ 0/32]	Time  0.655 ( 0.655)	Data  0.007 ( 0.007)	Loss 1.8590e-01 (1.8590e-01)	Acc@1  94.92 ( 94.92)	Acc@5 100.00 (100.00)
Epoch: [20][16/32]	Time  0.680 ( 0.666)	Data  0.006 ( 0.006)	Loss 2.2305e-01 (2.4564e-01)	Acc@1  93.75 ( 91.61)	Acc@5 100.00 ( 99.98)
Test Epoch: [20/200], lr: 0.000500, acc: 92.7750, best: 92.7750
Epoch: [21][ 0/32]	Time  0.655 ( 0.655)	Data  0.006 ( 0.006)	Loss 2.2610e-01 (2.2610e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [21][16/32]	Time  0.671 ( 0.669)	Data  0.006 ( 0.006)	Loss 2.5001e-01 (2.3072e-01)	Acc@1  91.41 ( 92.53)	Acc@5 100.00 ( 99.95)
Test Epoch: [21/200], lr: 0.000500, acc: 92.9500, best: 92.9500
Epoch: [22][ 0/32]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 1.8520e-01 (1.8520e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [22][16/32]	Time  0.658 ( 0.667)	Data  0.006 ( 0.006)	Loss 1.8015e-01 (2.1511e-01)	Acc@1  93.36 ( 92.65)	Acc@5  99.61 ( 99.98)
Test Epoch: [22/200], lr: 0.000500, acc: 92.3875, best: 92.9500
Epoch: [23][ 0/32]	Time  0.651 ( 0.651)	Data  0.006 ( 0.006)	Loss 2.0155e-01 (2.0155e-01)	Acc@1  91.80 ( 91.80)	Acc@5 100.00 (100.00)
Epoch: [23][16/32]	Time  0.656 ( 0.674)	Data  0.007 ( 0.006)	Loss 1.8458e-01 (2.3849e-01)	Acc@1  94.14 ( 92.21)	Acc@5 100.00 (100.00)
Test Epoch: [23/200], lr: 0.000500, acc: 93.2500, best: 93.2500
Epoch: [24][ 0/32]	Time  0.658 ( 0.658)	Data  0.006 ( 0.006)	Loss 2.1380e-01 (2.1380e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [24][16/32]	Time  0.663 ( 0.680)	Data  0.006 ( 0.006)	Loss 1.4603e-01 (2.0745e-01)	Acc@1  94.92 ( 92.78)	Acc@5 100.00 ( 99.98)
Test Epoch: [24/200], lr: 0.000500, acc: 91.5125, best: 93.2500
Epoch: [25][ 0/32]	Time  0.652 ( 0.652)	Data  0.006 ( 0.006)	Loss 2.9539e-01 (2.9539e-01)	Acc@1  90.23 ( 90.23)	Acc@5 100.00 (100.00)
Epoch: [25][16/32]	Time  0.670 ( 0.665)	Data  0.006 ( 0.006)	Loss 1.5274e-01 (1.8588e-01)	Acc@1  96.48 ( 94.44)	Acc@5 100.00 (100.00)
Test Epoch: [25/200], lr: 0.000500, acc: 94.5625, best: 94.5625
Epoch: [26][ 0/32]	Time  0.660 ( 0.660)	Data  0.007 ( 0.007)	Loss 1.1118e-01 (1.1118e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [26][16/32]	Time  0.667 ( 0.669)	Data  0.006 ( 0.010)	Loss 2.3696e-01 (1.7354e-01)	Acc@1  91.41 ( 94.62)	Acc@5 100.00 (100.00)
Test Epoch: [26/200], lr: 0.000500, acc: 93.3125, best: 94.5625
Epoch: [27][ 0/32]	Time  0.662 ( 0.662)	Data  0.006 ( 0.006)	Loss 2.1205e-01 (2.1205e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [27][16/32]	Time  0.656 ( 0.664)	Data  0.006 ( 0.006)	Loss 1.6302e-01 (1.8362e-01)	Acc@1  96.09 ( 94.03)	Acc@5 100.00 (100.00)
Test Epoch: [27/200], lr: 0.000500, acc: 94.6250, best: 94.6250
Epoch: [28][ 0/32]	Time  0.659 ( 0.659)	Data  0.006 ( 0.006)	Loss 1.4755e-01 (1.4755e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [28][16/32]	Time  0.661 ( 0.662)	Data  0.006 ( 0.006)	Loss 1.4442e-01 (1.6623e-01)	Acc@1  94.92 ( 94.44)	Acc@5 100.00 ( 99.98)
Test Epoch: [28/200], lr: 0.000500, acc: 95.2875, best: 95.2875
Epoch: [29][ 0/32]	Time  0.685 ( 0.685)	Data  0.007 ( 0.007)	Loss 1.6387e-01 (1.6387e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [29][16/32]	Time  0.683 ( 0.693)	Data  0.006 ( 0.006)	Loss 9.7146e-02 (1.4825e-01)	Acc@1  97.27 ( 95.01)	Acc@5 100.00 ( 99.98)
Test Epoch: [29/200], lr: 0.000500, acc: 95.2750, best: 95.2875
Epoch: [30][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 1.4242e-01 (1.4242e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [30][16/32]	Time  0.682 ( 0.693)	Data  0.006 ( 0.006)	Loss 1.4508e-01 (1.4098e-01)	Acc@1  95.70 ( 95.24)	Acc@5 100.00 (100.00)
Test Epoch: [30/200], lr: 0.000500, acc: 95.0125, best: 95.2875
Epoch: [31][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 1.3145e-01 (1.3145e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [31][16/32]	Time  0.688 ( 0.687)	Data  0.006 ( 0.006)	Loss 1.0648e-01 (1.3619e-01)	Acc@1  96.88 ( 95.77)	Acc@5 100.00 (100.00)
Test Epoch: [31/200], lr: 0.000500, acc: 95.6750, best: 95.6750
Epoch: [32][ 0/32]	Time  0.682 ( 0.682)	Data  0.006 ( 0.006)	Loss 1.3070e-01 (1.3070e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [32][16/32]	Time  0.683 ( 0.691)	Data  0.006 ( 0.006)	Loss 1.3874e-01 (1.5959e-01)	Acc@1  96.09 ( 94.51)	Acc@5 100.00 ( 99.98)
Test Epoch: [32/200], lr: 0.000500, acc: 94.8500, best: 95.6750
Epoch: [33][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 1.8622e-01 (1.8622e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [33][16/32]	Time  0.686 ( 0.686)	Data  0.006 ( 0.006)	Loss 1.3941e-01 (1.5841e-01)	Acc@1  96.09 ( 94.69)	Acc@5 100.00 (100.00)
Test Epoch: [33/200], lr: 0.000500, acc: 95.7250, best: 95.7250
Epoch: [34][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 1.1292e-01 (1.1292e-01)	Acc@1  95.70 ( 95.70)	Acc@5 100.00 (100.00)
Epoch: [34][16/32]	Time  0.681 ( 0.688)	Data  0.006 ( 0.006)	Loss 1.4257e-01 (1.3713e-01)	Acc@1  95.70 ( 95.52)	Acc@5 100.00 (100.00)
Test Epoch: [34/200], lr: 0.000500, acc: 95.6375, best: 95.7250
Epoch: [35][ 0/32]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 1.2598e-01 (1.2598e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [35][16/32]	Time  0.679 ( 0.696)	Data  0.006 ( 0.006)	Loss 1.3136e-01 (1.3334e-01)	Acc@1  95.70 ( 95.68)	Acc@5 100.00 (100.00)
Test Epoch: [35/200], lr: 0.000500, acc: 96.3375, best: 96.3375
Epoch: [36][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 8.8716e-02 (8.8716e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [36][16/32]	Time  0.677 ( 0.695)	Data  0.005 ( 0.006)	Loss 1.1557e-01 (1.3058e-01)	Acc@1  95.70 ( 95.89)	Acc@5 100.00 ( 99.98)
Test Epoch: [36/200], lr: 0.000500, acc: 96.0750, best: 96.3375
Epoch: [37][ 0/32]	Time  0.753 ( 0.753)	Data  0.006 ( 0.006)	Loss 1.4954e-01 (1.4954e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [37][16/32]	Time  0.752 ( 0.693)	Data  0.007 ( 0.006)	Loss 9.2804e-02 (1.3854e-01)	Acc@1  97.27 ( 95.34)	Acc@5 100.00 (100.00)
Test Epoch: [37/200], lr: 0.000500, acc: 95.7125, best: 96.3375
Epoch: [38][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 8.6786e-02 (8.6786e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [38][16/32]	Time  0.677 ( 0.680)	Data  0.005 ( 0.006)	Loss 1.5606e-01 (1.3975e-01)	Acc@1  93.75 ( 95.57)	Acc@5 100.00 (100.00)
Test Epoch: [38/200], lr: 0.000500, acc: 96.4375, best: 96.4375
Epoch: [39][ 0/32]	Time  0.683 ( 0.683)	Data  0.007 ( 0.007)	Loss 8.3807e-02 (8.3807e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [39][16/32]	Time  0.679 ( 0.682)	Data  0.006 ( 0.006)	Loss 1.5828e-01 (1.1693e-01)	Acc@1  94.92 ( 96.07)	Acc@5 100.00 (100.00)
Test Epoch: [39/200], lr: 0.000500, acc: 97.0500, best: 97.0500
Epoch: [40][ 0/32]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 1.1906e-01 (1.1906e-01)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [40][16/32]	Time  0.680 ( 0.686)	Data  0.006 ( 0.006)	Loss 1.3942e-01 (1.0729e-01)	Acc@1  93.75 ( 96.48)	Acc@5 100.00 (100.00)
Test Epoch: [40/200], lr: 0.000500, acc: 96.0750, best: 97.0500
Epoch: [41][ 0/32]	Time  0.717 ( 0.717)	Data  0.006 ( 0.006)	Loss 1.5515e-01 (1.5515e-01)	Acc@1  94.14 ( 94.14)	Acc@5 100.00 (100.00)
Epoch: [41][16/32]	Time  0.683 ( 0.687)	Data  0.007 ( 0.006)	Loss 9.8121e-02 (1.2214e-01)	Acc@1  98.44 ( 95.98)	Acc@5 100.00 (100.00)
Test Epoch: [41/200], lr: 0.000500, acc: 95.8000, best: 97.0500
Epoch: [42][ 0/32]	Time  0.674 ( 0.674)	Data  0.007 ( 0.007)	Loss 7.9674e-02 (7.9674e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [42][16/32]	Time  0.681 ( 0.695)	Data  0.006 ( 0.006)	Loss 9.6136e-02 (1.0747e-01)	Acc@1  95.70 ( 96.53)	Acc@5 100.00 (100.00)
Test Epoch: [42/200], lr: 0.000500, acc: 96.8250, best: 97.0500
Epoch: [43][ 0/32]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 8.1972e-02 (8.1972e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [43][16/32]	Time  0.685 ( 0.696)	Data  0.007 ( 0.006)	Loss 1.4244e-01 (1.1836e-01)	Acc@1  92.58 ( 96.14)	Acc@5 100.00 (100.00)
Test Epoch: [43/200], lr: 0.000500, acc: 96.9875, best: 97.0500
Epoch: [44][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 7.4567e-02 (7.4567e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [44][16/32]	Time  0.691 ( 0.688)	Data  0.006 ( 0.006)	Loss 1.1554e-01 (9.4746e-02)	Acc@1  95.31 ( 96.83)	Acc@5 100.00 (100.00)
Test Epoch: [44/200], lr: 0.000500, acc: 96.7000, best: 97.0500
Epoch: [45][ 0/32]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 1.0478e-01 (1.0478e-01)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [45][16/32]	Time  0.676 ( 0.685)	Data  0.006 ( 0.006)	Loss 9.9897e-02 (1.1930e-01)	Acc@1  96.09 ( 96.05)	Acc@5 100.00 (100.00)
Test Epoch: [45/200], lr: 0.000500, acc: 94.1625, best: 97.0500
Epoch: [46][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 9.0699e-02 (9.0699e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [46][16/32]	Time  0.681 ( 0.691)	Data  0.006 ( 0.006)	Loss 9.7871e-02 (1.1979e-01)	Acc@1  96.48 ( 96.14)	Acc@5 100.00 (100.00)
Test Epoch: [46/200], lr: 0.000500, acc: 96.2250, best: 97.0500
Epoch: [47][ 0/32]	Time  0.675 ( 0.675)	Data  0.008 ( 0.008)	Loss 1.3431e-01 (1.3431e-01)	Acc@1  94.92 ( 94.92)	Acc@5 100.00 (100.00)
Epoch: [47][16/32]	Time  0.693 ( 0.689)	Data  0.006 ( 0.006)	Loss 6.1869e-02 (9.8379e-02)	Acc@1  98.44 ( 96.90)	Acc@5 100.00 (100.00)
Test Epoch: [47/200], lr: 0.000500, acc: 97.6500, best: 97.6500
Epoch: [48][ 0/32]	Time  0.765 ( 0.765)	Data  0.006 ( 0.006)	Loss 8.4785e-02 (8.4785e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [48][16/32]	Time  0.679 ( 0.695)	Data  0.007 ( 0.006)	Loss 1.1215e-01 (8.8689e-02)	Acc@1  96.09 ( 96.92)	Acc@5 100.00 (100.00)
Test Epoch: [48/200], lr: 0.000500, acc: 97.4500, best: 97.6500
Epoch: [49][ 0/32]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 9.3588e-02 (9.3588e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [49][16/32]	Time  0.681 ( 0.695)	Data  0.006 ( 0.006)	Loss 9.5859e-02 (8.8882e-02)	Acc@1  96.09 ( 97.04)	Acc@5 100.00 (100.00)
Test Epoch: [49/200], lr: 0.000500, acc: 97.1625, best: 97.6500
Epoch: [50][ 0/32]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 6.5864e-02 (6.5864e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [50][16/32]	Time  0.735 ( 0.690)	Data  0.006 ( 0.006)	Loss 6.4170e-02 (8.1041e-02)	Acc@1  98.05 ( 97.38)	Acc@5 100.00 (100.00)
Test Epoch: [50/200], lr: 0.000500, acc: 97.2750, best: 97.6500
Epoch: [51][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 7.4739e-02 (7.4739e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [51][16/32]	Time  0.682 ( 0.686)	Data  0.006 ( 0.006)	Loss 1.4043e-01 (9.4790e-02)	Acc@1  94.53 ( 96.67)	Acc@5 100.00 (100.00)
Test Epoch: [51/200], lr: 0.000500, acc: 96.9125, best: 97.6500
Epoch: [52][ 0/32]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 9.0424e-02 (9.0424e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [52][16/32]	Time  0.683 ( 0.685)	Data  0.005 ( 0.006)	Loss 1.0590e-01 (8.8760e-02)	Acc@1  96.48 ( 96.99)	Acc@5 100.00 (100.00)
Test Epoch: [52/200], lr: 0.000500, acc: 97.3625, best: 97.6500
Epoch: [53][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 8.6683e-02 (8.6683e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [53][16/32]	Time  0.729 ( 0.689)	Data  0.006 ( 0.006)	Loss 6.1705e-02 (1.0641e-01)	Acc@1  98.44 ( 96.53)	Acc@5 100.00 (100.00)
Test Epoch: [53/200], lr: 0.000500, acc: 97.3625, best: 97.6500
Epoch: [54][ 0/32]	Time  0.676 ( 0.676)	Data  0.008 ( 0.008)	Loss 1.0619e-01 (1.0619e-01)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [54][16/32]	Time  0.681 ( 0.687)	Data  0.006 ( 0.006)	Loss 7.1897e-02 (8.1948e-02)	Acc@1  96.48 ( 97.40)	Acc@5 100.00 (100.00)
Test Epoch: [54/200], lr: 0.000500, acc: 97.5625, best: 97.6500
Epoch: [55][ 0/32]	Time  0.683 ( 0.683)	Data  0.008 ( 0.008)	Loss 1.0540e-01 (1.0540e-01)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [55][16/32]	Time  0.678 ( 0.696)	Data  0.006 ( 0.006)	Loss 9.1581e-02 (7.8484e-02)	Acc@1  95.70 ( 97.06)	Acc@5 100.00 (100.00)
Test Epoch: [55/200], lr: 0.000500, acc: 96.9250, best: 97.6500
Epoch: [56][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 5.5449e-02 (5.5449e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [56][16/32]	Time  0.677 ( 0.697)	Data  0.006 ( 0.006)	Loss 4.8931e-02 (8.4796e-02)	Acc@1  98.44 ( 97.22)	Acc@5 100.00 (100.00)
Test Epoch: [56/200], lr: 0.000500, acc: 97.6125, best: 97.6500
Epoch: [57][ 0/32]	Time  0.680 ( 0.680)	Data  0.006 ( 0.006)	Loss 6.6386e-02 (6.6386e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [57][16/32]	Time  0.688 ( 0.687)	Data  0.006 ( 0.006)	Loss 5.1170e-02 (7.5834e-02)	Acc@1  98.05 ( 97.29)	Acc@5 100.00 (100.00)
Test Epoch: [57/200], lr: 0.000500, acc: 97.7875, best: 97.7875
Epoch: [58][ 0/32]	Time  0.680 ( 0.680)	Data  0.007 ( 0.007)	Loss 7.0092e-02 (7.0092e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [58][16/32]	Time  0.686 ( 0.692)	Data  0.006 ( 0.006)	Loss 7.4835e-02 (7.7091e-02)	Acc@1  98.05 ( 97.22)	Acc@5 100.00 (100.00)
Test Epoch: [58/200], lr: 0.000500, acc: 97.7250, best: 97.7875
Epoch: [59][ 0/32]	Time  0.735 ( 0.735)	Data  0.007 ( 0.007)	Loss 8.7648e-02 (8.7648e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [59][16/32]	Time  0.690 ( 0.693)	Data  0.006 ( 0.011)	Loss 4.9863e-02 (7.1997e-02)	Acc@1  98.83 ( 97.63)	Acc@5 100.00 (100.00)
Test Epoch: [59/200], lr: 0.000500, acc: 97.7750, best: 97.7875
Epoch: [60][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 6.3530e-02 (6.3530e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [60][16/32]	Time  0.685 ( 0.692)	Data  0.007 ( 0.006)	Loss 4.5856e-02 (5.9859e-02)	Acc@1  98.83 ( 97.79)	Acc@5 100.00 (100.00)
Test Epoch: [60/200], lr: 0.000050, acc: 98.4250, best: 98.4250
Epoch: [61][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 5.6154e-02 (5.6154e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [61][16/32]	Time  0.727 ( 0.694)	Data  0.005 ( 0.006)	Loss 5.5918e-02 (5.2888e-02)	Acc@1  97.66 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [61/200], lr: 0.000050, acc: 98.3625, best: 98.4250
Epoch: [62][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 6.4197e-02 (6.4197e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [62][16/32]	Time  0.680 ( 0.683)	Data  0.006 ( 0.006)	Loss 5.0168e-02 (5.3915e-02)	Acc@1  98.44 ( 98.23)	Acc@5 100.00 (100.00)
Test Epoch: [62/200], lr: 0.000050, acc: 98.4000, best: 98.4250
Epoch: [63][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 5.5512e-02 (5.5512e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [63][16/32]	Time  0.684 ( 0.681)	Data  0.007 ( 0.006)	Loss 3.9871e-02 (5.7033e-02)	Acc@1  98.05 ( 98.09)	Acc@5 100.00 (100.00)
Test Epoch: [63/200], lr: 0.000050, acc: 98.3750, best: 98.4250
Epoch: [64][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 6.1946e-02 (6.1946e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [64][16/32]	Time  0.690 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.6852e-02 (4.8890e-02)	Acc@1  98.83 ( 98.37)	Acc@5 100.00 (100.00)
Test Epoch: [64/200], lr: 0.000050, acc: 98.5250, best: 98.5250
Epoch: [65][ 0/32]	Time  0.674 ( 0.674)	Data  0.007 ( 0.007)	Loss 3.7082e-02 (3.7082e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [65][16/32]	Time  0.684 ( 0.684)	Data  0.005 ( 0.006)	Loss 3.9201e-02 (5.0858e-02)	Acc@1  99.61 ( 98.62)	Acc@5 100.00 (100.00)
Test Epoch: [65/200], lr: 0.000050, acc: 98.4000, best: 98.5250
Epoch: [66][ 0/32]	Time  0.681 ( 0.681)	Data  0.007 ( 0.007)	Loss 5.1055e-02 (5.1055e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [66][16/32]	Time  0.686 ( 0.691)	Data  0.006 ( 0.006)	Loss 4.4623e-02 (5.0336e-02)	Acc@1  98.83 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [66/200], lr: 0.000050, acc: 98.3250, best: 98.5250
Epoch: [67][ 0/32]	Time  0.684 ( 0.684)	Data  0.007 ( 0.007)	Loss 4.4482e-02 (4.4482e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [67][16/32]	Time  0.681 ( 0.692)	Data  0.006 ( 0.006)	Loss 5.5770e-02 (5.2011e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 (100.00)
Test Epoch: [67/200], lr: 0.000050, acc: 98.5375, best: 98.5375
Epoch: [68][ 0/32]	Time  0.684 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.3507e-02 (4.3507e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [68][16/32]	Time  0.688 ( 0.691)	Data  0.006 ( 0.006)	Loss 6.2155e-02 (5.1335e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [68/200], lr: 0.000050, acc: 98.4625, best: 98.5375
Epoch: [69][ 0/32]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 5.0608e-02 (5.0608e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [69][16/32]	Time  0.690 ( 0.689)	Data  0.006 ( 0.006)	Loss 6.1062e-02 (5.4744e-02)	Acc@1  98.05 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [69/200], lr: 0.000050, acc: 98.3375, best: 98.5375
Epoch: [70][ 0/32]	Time  0.692 ( 0.692)	Data  0.007 ( 0.007)	Loss 7.9931e-02 (7.9931e-02)	Acc@1  95.70 ( 95.70)	Acc@5 100.00 (100.00)
Epoch: [70][16/32]	Time  0.685 ( 0.688)	Data  0.006 ( 0.006)	Loss 4.1238e-02 (5.3278e-02)	Acc@1  98.83 ( 98.30)	Acc@5 100.00 (100.00)
Test Epoch: [70/200], lr: 0.000050, acc: 98.4750, best: 98.5375
Epoch: [71][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.6920e-02 (5.6920e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [71][16/32]	Time  0.684 ( 0.688)	Data  0.005 ( 0.006)	Loss 3.8515e-02 (4.7456e-02)	Acc@1  99.61 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [71/200], lr: 0.000050, acc: 98.4125, best: 98.5375
Epoch: [72][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 7.7679e-02 (7.7679e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [72][16/32]	Time  0.681 ( 0.692)	Data  0.005 ( 0.006)	Loss 6.6050e-02 (4.8805e-02)	Acc@1  97.66 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [72/200], lr: 0.000050, acc: 98.5375, best: 98.5375
Epoch: [73][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.9364e-02 (5.9364e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [73][16/32]	Time  0.681 ( 0.696)	Data  0.006 ( 0.006)	Loss 3.2396e-02 (4.7573e-02)	Acc@1  99.61 ( 98.60)	Acc@5 100.00 (100.00)
Test Epoch: [73/200], lr: 0.000050, acc: 98.4250, best: 98.5375
Epoch: [74][ 0/32]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 3.4361e-02 (3.4361e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [74][16/32]	Time  0.682 ( 0.697)	Data  0.006 ( 0.006)	Loss 6.0131e-02 (4.8900e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [74/200], lr: 0.000050, acc: 98.5375, best: 98.5375
Epoch: [75][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 5.8242e-02 (5.8242e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [75][16/32]	Time  0.684 ( 0.692)	Data  0.006 ( 0.006)	Loss 5.9388e-02 (4.9739e-02)	Acc@1  97.27 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [75/200], lr: 0.000050, acc: 98.4625, best: 98.5375
Epoch: [76][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 3.2813e-02 (3.2813e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [76][16/32]	Time  0.687 ( 0.685)	Data  0.006 ( 0.006)	Loss 6.3810e-02 (4.8470e-02)	Acc@1  97.27 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [76/200], lr: 0.000050, acc: 98.6625, best: 98.6625
Epoch: [77][ 0/32]	Time  0.757 ( 0.757)	Data  0.006 ( 0.006)	Loss 5.4198e-02 (5.4198e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [77][16/32]	Time  0.676 ( 0.686)	Data  0.006 ( 0.006)	Loss 6.5516e-02 (4.8581e-02)	Acc@1  98.05 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [77/200], lr: 0.000050, acc: 98.4250, best: 98.6625
Epoch: [78][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 3.9442e-02 (3.9442e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [78][16/32]	Time  0.681 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.6321e-02 (4.8183e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [78/200], lr: 0.000050, acc: 98.6875, best: 98.6875
Epoch: [79][ 0/32]	Time  0.671 ( 0.671)	Data  0.007 ( 0.007)	Loss 3.0527e-02 (3.0527e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [79][16/32]	Time  0.678 ( 0.693)	Data  0.006 ( 0.006)	Loss 5.0994e-02 (5.0409e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [79/200], lr: 0.000050, acc: 98.4250, best: 98.6875
Epoch: [80][ 0/32]	Time  0.690 ( 0.690)	Data  0.007 ( 0.007)	Loss 5.1294e-02 (5.1294e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [80][16/32]	Time  0.683 ( 0.695)	Data  0.006 ( 0.006)	Loss 4.4884e-02 (4.8344e-02)	Acc@1  99.61 ( 98.35)	Acc@5 100.00 (100.00)
Test Epoch: [80/200], lr: 0.000005, acc: 98.4750, best: 98.6875
Epoch: [81][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 2.6987e-02 (2.6987e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [81][16/32]	Time  0.744 ( 0.690)	Data  0.006 ( 0.006)	Loss 5.9250e-02 (4.6960e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Test Epoch: [81/200], lr: 0.000005, acc: 98.5875, best: 98.6875
Epoch: [82][ 0/32]	Time  0.680 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.8765e-02 (4.8765e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [82][16/32]	Time  0.682 ( 0.687)	Data  0.008 ( 0.006)	Loss 4.5127e-02 (4.7884e-02)	Acc@1  99.61 ( 98.53)	Acc@5 100.00 (100.00)
Test Epoch: [82/200], lr: 0.000005, acc: 98.6250, best: 98.6875
Epoch: [83][ 0/32]	Time  0.683 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.1980e-02 (4.1980e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [83][16/32]	Time  0.678 ( 0.683)	Data  0.006 ( 0.006)	Loss 6.5969e-02 (4.6538e-02)	Acc@1  98.05 ( 98.62)	Acc@5 100.00 (100.00)
Test Epoch: [83/200], lr: 0.000005, acc: 98.6750, best: 98.6875
Epoch: [84][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 4.9297e-02 (4.9297e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [84][16/32]	Time  0.686 ( 0.684)	Data  0.007 ( 0.006)	Loss 5.1007e-02 (4.7100e-02)	Acc@1  98.05 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [84/200], lr: 0.000005, acc: 98.6375, best: 98.6875
Epoch: [85][ 0/32]	Time  0.723 ( 0.723)	Data  0.006 ( 0.006)	Loss 3.7220e-02 (3.7220e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [85][16/32]	Time  0.676 ( 0.691)	Data  0.006 ( 0.006)	Loss 3.1578e-02 (4.6374e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 (100.00)
Test Epoch: [85/200], lr: 0.000005, acc: 98.6875, best: 98.6875
Epoch: [86][ 0/32]	Time  0.690 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.5210e-02 (4.5210e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [86][16/32]	Time  0.679 ( 0.694)	Data  0.006 ( 0.006)	Loss 3.7649e-02 (4.8025e-02)	Acc@1  99.22 ( 98.58)	Acc@5 100.00 (100.00)
Test Epoch: [86/200], lr: 0.000005, acc: 98.6750, best: 98.6875
Epoch: [87][ 0/32]	Time  0.680 ( 0.680)	Data  0.006 ( 0.006)	Loss 6.6565e-02 (6.6565e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [87][16/32]	Time  0.679 ( 0.692)	Data  0.006 ( 0.006)	Loss 2.9759e-02 (4.5953e-02)	Acc@1  99.61 ( 98.76)	Acc@5 100.00 (100.00)
Test Epoch: [87/200], lr: 0.000005, acc: 98.7000, best: 98.7000
Epoch: [88][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.8264e-02 (4.8264e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [88][16/32]	Time  0.685 ( 0.690)	Data  0.007 ( 0.006)	Loss 3.9435e-02 (4.7342e-02)	Acc@1  98.83 ( 98.78)	Acc@5 100.00 (100.00)
Test Epoch: [88/200], lr: 0.000005, acc: 98.6875, best: 98.7000
Epoch: [89][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.7741e-02 (4.7741e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [89][16/32]	Time  0.684 ( 0.687)	Data  0.006 ( 0.011)	Loss 8.3974e-02 (4.9004e-02)	Acc@1  96.09 ( 98.37)	Acc@5 100.00 (100.00)
Test Epoch: [89/200], lr: 0.000005, acc: 98.6250, best: 98.7000
Epoch: [90][ 0/32]	Time  0.676 ( 0.676)	Data  0.009 ( 0.009)	Loss 4.0857e-02 (4.0857e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [90][16/32]	Time  0.684 ( 0.687)	Data  0.007 ( 0.011)	Loss 4.0147e-02 (4.7823e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Test Epoch: [90/200], lr: 0.000005, acc: 98.6750, best: 98.7000
Epoch: [91][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.0315e-02 (5.0315e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [91][16/32]	Time  0.689 ( 0.689)	Data  0.007 ( 0.011)	Loss 4.8628e-02 (4.7794e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [91/200], lr: 0.000005, acc: 98.5875, best: 98.7000
Epoch: [92][ 0/32]	Time  0.691 ( 0.691)	Data  0.006 ( 0.006)	Loss 6.3850e-02 (6.3850e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [92][16/32]	Time  0.682 ( 0.695)	Data  0.007 ( 0.011)	Loss 5.2416e-02 (4.3725e-02)	Acc@1  98.83 ( 98.90)	Acc@5 100.00 (100.00)
Test Epoch: [92/200], lr: 0.000005, acc: 98.6250, best: 98.7000
Epoch: [93][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.8948e-02 (4.8948e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [93][16/32]	Time  0.701 ( 0.691)	Data  0.006 ( 0.006)	Loss 4.5439e-02 (4.4654e-02)	Acc@1  98.83 ( 98.78)	Acc@5 100.00 (100.00)
Test Epoch: [93/200], lr: 0.000005, acc: 98.6125, best: 98.7000
Epoch: [94][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 8.1684e-02 (8.1684e-02)	Acc@1  95.70 ( 95.70)	Acc@5 100.00 (100.00)
Epoch: [94][16/32]	Time  0.701 ( 0.688)	Data  0.006 ( 0.006)	Loss 3.7436e-02 (4.9342e-02)	Acc@1  99.61 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [94/200], lr: 0.000005, acc: 98.7125, best: 98.7125
Epoch: [95][ 0/32]	Time  0.691 ( 0.691)	Data  0.007 ( 0.007)	Loss 4.2771e-02 (4.2771e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [95][16/32]	Time  0.688 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.7365e-02 (4.6051e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Test Epoch: [95/200], lr: 0.000005, acc: 98.6875, best: 98.7125
Epoch: [96][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 3.5365e-02 (3.5365e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [96][16/32]	Time  0.675 ( 0.689)	Data  0.006 ( 0.006)	Loss 4.3505e-02 (4.0439e-02)	Acc@1  98.05 ( 98.97)	Acc@5 100.00 (100.00)
Test Epoch: [96/200], lr: 0.000005, acc: 98.5250, best: 98.7125
Epoch: [97][ 0/32]	Time  0.680 ( 0.680)	Data  0.006 ( 0.006)	Loss 3.5334e-02 (3.5334e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [97][16/32]	Time  0.684 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.3519e-02 (4.5383e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [97/200], lr: 0.000005, acc: 98.7000, best: 98.7125
Epoch: [98][ 0/32]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 6.0747e-02 (6.0747e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [98][16/32]	Time  0.689 ( 0.689)	Data  0.006 ( 0.011)	Loss 3.8174e-02 (4.5905e-02)	Acc@1  99.22 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [98/200], lr: 0.000005, acc: 98.6625, best: 98.7125
Epoch: [99][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 3.5582e-02 (3.5582e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [99][16/32]	Time  0.675 ( 0.689)	Data  0.006 ( 0.006)	Loss 5.8066e-02 (4.3561e-02)	Acc@1  98.05 ( 98.76)	Acc@5 100.00 (100.00)
Test Epoch: [99/200], lr: 0.000005, acc: 98.6125, best: 98.7125
Epoch: [100][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.1524e-02 (4.1524e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [100][16/32]	Time  0.688 ( 0.686)	Data  0.006 ( 0.006)	Loss 5.2683e-02 (4.8265e-02)	Acc@1  98.05 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [100/200], lr: 0.000005, acc: 98.6250, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [101][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.8366e-02 (5.8366e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [101][16/32]	Time  0.680 ( 0.683)	Data  0.005 ( 0.006)	Loss 3.9726e-02 (4.4929e-02)	Acc@1  99.61 ( 98.85)	Acc@5 100.00 (100.00)
Test Epoch: [101/200], lr: 0.000005, acc: 98.6500, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [102][ 0/32]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 6.0352e-02 (6.0352e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [102][16/32]	Time  0.685 ( 0.682)	Data  0.006 ( 0.006)	Loss 5.3144e-02 (4.9011e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Test Epoch: [102/200], lr: 0.000005, acc: 98.6000, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [103][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 3.0067e-02 (3.0067e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [103][16/32]	Time  0.683 ( 0.685)	Data  0.006 ( 0.006)	Loss 4.4252e-02 (4.5081e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Test Epoch: [103/200], lr: 0.000005, acc: 98.7125, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [104][ 0/32]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 5.8347e-02 (5.8347e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [104][16/32]	Time  0.686 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.2024e-02 (5.0209e-02)	Acc@1  99.22 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [104/200], lr: 0.000005, acc: 98.5875, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [105][ 0/32]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.7715e-02 (4.7715e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [105][16/32]	Time  0.679 ( 0.684)	Data  0.006 ( 0.006)	Loss 2.8938e-02 (4.5363e-02)	Acc@1  99.61 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [105/200], lr: 0.000005, acc: 98.6000, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [106][ 0/32]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 3.1171e-02 (3.1171e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [106][16/32]	Time  0.679 ( 0.683)	Data  0.006 ( 0.006)	Loss 3.5127e-02 (4.2434e-02)	Acc@1  99.22 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [106/200], lr: 0.000005, acc: 98.6125, best: 98.7125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [107][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.5017e-02 (6.5017e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [107][16/32]	Time  0.681 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.8331e-02 (5.0647e-02)	Acc@1  98.83 ( 98.37)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [107/200], lr: 0.000005, acc: 98.6750, best: 98.7125
Epoch: [108][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 6.6207e-02 (6.6207e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [108][16/32]	Time  0.685 ( 0.685)	Data  0.006 ( 0.006)	Loss 4.9132e-02 (4.8614e-02)	Acc@1  98.83 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [108/200], lr: 0.000005, acc: 98.7250, best: 98.7250
Epoch: [109][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.3237e-02 (5.3237e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [109][16/32]	Time  0.684 ( 0.687)	Data  0.006 ( 0.006)	Loss 4.7918e-02 (4.7502e-02)	Acc@1  98.05 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [109/200], lr: 0.000005, acc: 98.5875, best: 98.7250
Epoch: [110][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 4.3769e-02 (4.3769e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [110][16/32]	Time  0.681 ( 0.680)	Data  0.006 ( 0.006)	Loss 6.0201e-02 (4.7117e-02)	Acc@1  97.66 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [110/200], lr: 0.000005, acc: 98.6625, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [111][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 7.1783e-02 (7.1783e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [111][16/32]	Time  0.692 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.9807e-02 (5.4199e-02)	Acc@1  99.22 ( 98.58)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [111/200], lr: 0.000005, acc: 98.6250, best: 98.7250
Epoch: [112][ 0/32]	Time  0.687 ( 0.687)	Data  0.006 ( 0.006)	Loss 5.2220e-02 (5.2220e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [112][16/32]	Time  0.677 ( 0.684)	Data  0.006 ( 0.006)	Loss 5.1892e-02 (4.8615e-02)	Acc@1  98.05 ( 98.46)	Acc@5 100.00 (100.00)
Test Epoch: [112/200], lr: 0.000005, acc: 98.6750, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [113][ 0/32]	Time  0.681 ( 0.681)	Data  0.007 ( 0.007)	Loss 3.6219e-02 (3.6219e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [113][16/32]	Time  0.685 ( 0.685)	Data  0.006 ( 0.006)	Loss 4.0431e-02 (4.7063e-02)	Acc@1  98.83 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [113/200], lr: 0.000005, acc: 98.6000, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [114][ 0/32]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 3.1162e-02 (3.1162e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [114][16/32]	Time  0.684 ( 0.682)	Data  0.006 ( 0.006)	Loss 3.0834e-02 (4.7261e-02)	Acc@1  98.83 ( 98.69)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [114/200], lr: 0.000005, acc: 98.6250, best: 98.7250
Epoch: [115][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 4.1513e-02 (4.1513e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [115][16/32]	Time  0.679 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.3790e-02 (5.0078e-02)	Acc@1  98.83 ( 98.32)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [115/200], lr: 0.000005, acc: 98.5125, best: 98.7250
Epoch: [116][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.2098e-02 (4.2098e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [116][16/32]	Time  0.690 ( 0.683)	Data  0.005 ( 0.006)	Loss 3.9638e-02 (4.9369e-02)	Acc@1  99.61 ( 98.55)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [116/200], lr: 0.000005, acc: 98.5875, best: 98.7250
Epoch: [117][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 2.7016e-02 (2.7016e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [117][16/32]	Time  0.689 ( 0.685)	Data  0.006 ( 0.006)	Loss 4.2944e-02 (4.9680e-02)	Acc@1  98.05 ( 98.51)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [117/200], lr: 0.000005, acc: 98.7000, best: 98.7250
Epoch: [118][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 4.9934e-02 (4.9934e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [118][16/32]	Time  0.680 ( 0.681)	Data  0.006 ( 0.006)	Loss 4.1991e-02 (4.4399e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Test Epoch: [118/200], lr: 0.000005, acc: 98.7250, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [119][ 0/32]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 3.7737e-02 (3.7737e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [119][16/32]	Time  0.686 ( 0.686)	Data  0.006 ( 0.006)	Loss 4.2166e-02 (4.6948e-02)	Acc@1  97.66 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [119/200], lr: 0.000005, acc: 98.6500, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [120][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 3.9336e-02 (3.9336e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [120][16/32]	Time  0.682 ( 0.685)	Data  0.006 ( 0.006)	Loss 5.6534e-02 (4.8914e-02)	Acc@1  97.27 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [120/200], lr: 0.000005, acc: 98.6000, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [121][ 0/32]	Time  0.681 ( 0.681)	Data  0.007 ( 0.007)	Loss 5.3864e-02 (5.3864e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [121][16/32]	Time  0.679 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.8690e-02 (4.2735e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [121/200], lr: 0.000005, acc: 98.5875, best: 98.7250
Epoch: [122][ 0/32]	Time  0.674 ( 0.674)	Data  0.007 ( 0.007)	Loss 3.4255e-02 (3.4255e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [122][16/32]	Time  0.679 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.9864e-02 (4.7415e-02)	Acc@1  98.05 ( 98.48)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [122/200], lr: 0.000005, acc: 98.5250, best: 98.7250
Epoch: [123][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 5.2935e-02 (5.2935e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [123][16/32]	Time  0.682 ( 0.684)	Data  0.005 ( 0.006)	Loss 3.3491e-02 (4.7178e-02)	Acc@1  99.22 ( 98.60)	Acc@5 100.00 (100.00)
Test Epoch: [123/200], lr: 0.000005, acc: 98.5500, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [124][ 0/32]	Time  0.680 ( 0.680)	Data  0.007 ( 0.007)	Loss 5.4273e-02 (5.4273e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [124][16/32]	Time  0.678 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.4891e-02 (4.4355e-02)	Acc@1  98.05 ( 98.74)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [124/200], lr: 0.000005, acc: 98.5125, best: 98.7250
Epoch: [125][ 0/32]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 4.0056e-02 (4.0056e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [125][16/32]	Time  0.677 ( 0.687)	Data  0.006 ( 0.006)	Loss 4.7732e-02 (4.6847e-02)	Acc@1  98.83 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [125/200], lr: 0.000005, acc: 98.5750, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [126][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 3.5918e-02 (3.5918e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [126][16/32]	Time  0.693 ( 0.684)	Data  0.006 ( 0.006)	Loss 3.1537e-02 (4.6273e-02)	Acc@1  99.61 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [126/200], lr: 0.000005, acc: 98.6250, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [127][ 0/32]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 4.8486e-02 (4.8486e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [127][16/32]	Time  0.683 ( 0.681)	Data  0.006 ( 0.006)	Loss 5.9063e-02 (4.5381e-02)	Acc@1  98.05 ( 98.62)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [127/200], lr: 0.000005, acc: 98.5250, best: 98.7250
Epoch: [128][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 7.4578e-02 (7.4578e-02)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [128][16/32]	Time  0.684 ( 0.681)	Data  0.007 ( 0.006)	Loss 5.5815e-02 (4.6963e-02)	Acc@1  98.05 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [128/200], lr: 0.000005, acc: 98.5250, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [129][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 3.4605e-02 (3.4605e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [129][16/32]	Time  0.684 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.9488e-02 (4.5164e-02)	Acc@1  98.44 ( 98.60)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [129/200], lr: 0.000005, acc: 98.6375, best: 98.7250
Epoch: [130][ 0/32]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 4.8886e-02 (4.8886e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [130][16/32]	Time  0.682 ( 0.684)	Data  0.007 ( 0.006)	Loss 7.1081e-02 (5.0128e-02)	Acc@1  96.88 ( 98.32)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [130/200], lr: 0.000005, acc: 98.7000, best: 98.7250
Epoch: [131][ 0/32]	Time  0.675 ( 0.675)	Data  0.008 ( 0.008)	Loss 4.6657e-02 (4.6657e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [131][16/32]	Time  0.680 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.3177e-02 (4.5926e-02)	Acc@1  98.83 ( 98.44)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [131/200], lr: 0.000005, acc: 98.7000, best: 98.7250
Epoch: [132][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 7.4267e-02 (7.4267e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [132][16/32]	Time  0.686 ( 0.685)	Data  0.006 ( 0.006)	Loss 3.5337e-02 (4.6689e-02)	Acc@1  99.22 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [132/200], lr: 0.000005, acc: 98.5625, best: 98.7250
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [133][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 6.8197e-02 (6.8197e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [133][16/32]	Time  0.694 ( 0.683)	Data  0.006 ( 0.006)	Loss 5.5315e-02 (4.4290e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [133/200], lr: 0.000005, acc: 98.6750, best: 98.7250
Epoch: [134][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.3956e-02 (5.3956e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [134][16/32]	Time  0.675 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.1120e-02 (4.8778e-02)	Acc@1  99.22 ( 98.62)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [134/200], lr: 0.000005, acc: 98.5500, best: 98.7250
Epoch: [135][ 0/32]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 3.9797e-02 (3.9797e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [135][16/32]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 3.7741e-02 (4.8547e-02)	Acc@1  99.22 ( 98.46)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [135/200], lr: 0.000005, acc: 98.7250, best: 98.7250
Epoch: [136][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.7172e-02 (4.7172e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [136][16/32]	Time  0.679 ( 0.683)	Data  0.006 ( 0.006)	Loss 3.5068e-02 (4.5534e-02)	Acc@1  99.61 ( 98.94)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [136/200], lr: 0.000005, acc: 98.5125, best: 98.7250
Epoch: [137][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.2039e-02 (6.2039e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [137][16/32]	Time  0.676 ( 0.683)	Data  0.006 ( 0.006)	Loss 3.5516e-02 (4.5505e-02)	Acc@1  99.61 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [137/200], lr: 0.000005, acc: 98.7625, best: 98.7625
Epoch: [138][ 0/32]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 4.6022e-02 (4.6022e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [138][16/32]	Time  0.683 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.9980e-02 (4.5740e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [138/200], lr: 0.000005, acc: 98.6875, best: 98.7625
Epoch: [139][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.8556e-02 (4.8556e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [139][16/32]	Time  0.685 ( 0.682)	Data  0.006 ( 0.006)	Loss 3.4095e-02 (4.2968e-02)	Acc@1  98.83 ( 98.76)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [139/200], lr: 0.000005, acc: 98.7125, best: 98.7625
Epoch: [140][ 0/32]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 5.8921e-02 (5.8921e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [140][16/32]	Time  0.685 ( 0.680)	Data  0.007 ( 0.006)	Loss 3.2432e-02 (4.6227e-02)	Acc@1  99.61 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [140/200], lr: 0.000005, acc: 98.7000, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [141][ 0/32]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 7.5504e-02 (7.5504e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [141][16/32]	Time  0.676 ( 0.683)	Data  0.006 ( 0.006)	Loss 3.0062e-02 (4.6253e-02)	Acc@1  99.61 ( 98.58)	Acc@5 100.00 (100.00)
Test Epoch: [141/200], lr: 0.000005, acc: 98.7250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [142][ 0/32]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 2.8832e-02 (2.8832e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [142][16/32]	Time  0.682 ( 0.682)	Data  0.007 ( 0.006)	Loss 4.2006e-02 (4.7206e-02)	Acc@1  98.83 ( 98.55)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [142/200], lr: 0.000005, acc: 98.7000, best: 98.7625
Epoch: [143][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 3.0897e-02 (3.0897e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [143][16/32]	Time  0.686 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.5869e-02 (4.3133e-02)	Acc@1  98.83 ( 98.71)	Acc@5 100.00 (100.00)
Test Epoch: [143/200], lr: 0.000005, acc: 98.6625, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [144][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.0337e-02 (5.0337e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [144][16/32]	Time  0.682 ( 0.683)	Data  0.007 ( 0.006)	Loss 4.6338e-02 (4.4800e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [144/200], lr: 0.000005, acc: 98.7250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [145][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 3.8246e-02 (3.8246e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [145][16/32]	Time  0.681 ( 0.682)	Data  0.006 ( 0.006)	Loss 5.7511e-02 (4.3992e-02)	Acc@1  98.05 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [145/200], lr: 0.000005, acc: 98.6375, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [146][ 0/32]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.1571e-02 (4.1571e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [146][16/32]	Time  0.688 ( 0.689)	Data  0.006 ( 0.011)	Loss 3.2850e-02 (4.4615e-02)	Acc@1  99.61 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [146/200], lr: 0.000005, acc: 98.7125, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [147][ 0/32]	Time  0.765 ( 0.765)	Data  0.006 ( 0.006)	Loss 4.4469e-02 (4.4469e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [147][16/32]	Time  0.686 ( 0.688)	Data  0.007 ( 0.006)	Loss 4.7994e-02 (4.7624e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [147/200], lr: 0.000005, acc: 98.4500, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [148][ 0/32]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 3.5720e-02 (3.5720e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [148][16/32]	Time  0.680 ( 0.695)	Data  0.006 ( 0.006)	Loss 2.3469e-02 (4.3168e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [148/200], lr: 0.000005, acc: 98.6750, best: 98.7625
Epoch: [149][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.0625e-02 (5.0625e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [149][16/32]	Time  0.693 ( 0.697)	Data  0.006 ( 0.006)	Loss 4.3866e-02 (4.5797e-02)	Acc@1  98.83 ( 98.55)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [149/200], lr: 0.000005, acc: 98.6625, best: 98.7625
Epoch: [150][ 0/32]	Time  0.711 ( 0.711)	Data  0.006 ( 0.006)	Loss 3.1927e-02 (3.1927e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [150][16/32]	Time  0.678 ( 0.692)	Data  0.006 ( 0.006)	Loss 5.1371e-02 (4.4546e-02)	Acc@1  98.44 ( 98.83)	Acc@5 100.00 (100.00)
Test Epoch: [150/200], lr: 0.000005, acc: 98.6625, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [151][ 0/32]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 3.5760e-02 (3.5760e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [151][16/32]	Time  0.708 ( 0.685)	Data  0.006 ( 0.006)	Loss 3.5476e-02 (4.5236e-02)	Acc@1  98.83 ( 98.78)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [151/200], lr: 0.000005, acc: 98.6125, best: 98.7625
Epoch: [152][ 0/32]	Time  0.689 ( 0.689)	Data  0.007 ( 0.007)	Loss 5.6507e-02 (5.6507e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [152][16/32]	Time  0.686 ( 0.688)	Data  0.006 ( 0.006)	Loss 4.2442e-02 (4.3105e-02)	Acc@1  99.22 ( 98.62)	Acc@5 100.00 (100.00)
Test Epoch: [152/200], lr: 0.000005, acc: 98.5750, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [153][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 4.2367e-02 (4.2367e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [153][16/32]	Time  0.685 ( 0.689)	Data  0.006 ( 0.006)	Loss 3.4650e-02 (4.9237e-02)	Acc@1  99.22 ( 98.41)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [153/200], lr: 0.000005, acc: 98.7000, best: 98.7625
Epoch: [154][ 0/32]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.0043e-02 (4.0043e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [154][16/32]	Time  0.682 ( 0.688)	Data  0.006 ( 0.006)	Loss 4.0757e-02 (4.6059e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Test Epoch: [154/200], lr: 0.000005, acc: 98.6000, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [155][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 3.9296e-02 (3.9296e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [155][16/32]	Time  0.678 ( 0.687)	Data  0.006 ( 0.006)	Loss 5.6825e-02 (4.5429e-02)	Acc@1  98.44 ( 98.62)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [155/200], lr: 0.000005, acc: 98.6375, best: 98.7625
Epoch: [156][ 0/32]	Time  0.669 ( 0.669)	Data  0.006 ( 0.006)	Loss 3.7020e-02 (3.7020e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [156][16/32]	Time  0.694 ( 0.688)	Data  0.006 ( 0.006)	Loss 4.6065e-02 (4.6494e-02)	Acc@1  98.83 ( 98.62)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [156/200], lr: 0.000005, acc: 98.6250, best: 98.7625
Epoch: [157][ 0/32]	Time  0.673 ( 0.673)	Data  0.008 ( 0.008)	Loss 4.6263e-02 (4.6263e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [157][16/32]	Time  0.683 ( 0.688)	Data  0.006 ( 0.006)	Loss 3.7623e-02 (4.2221e-02)	Acc@1  99.22 ( 98.81)	Acc@5 100.00 (100.00)
Test Epoch: [157/200], lr: 0.000005, acc: 98.6375, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [158][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 2.5425e-02 (2.5425e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [158][16/32]	Time  0.681 ( 0.686)	Data  0.007 ( 0.006)	Loss 5.6341e-02 (4.2202e-02)	Acc@1  98.44 ( 98.85)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [158/200], lr: 0.000005, acc: 98.6000, best: 98.7625
Epoch: [159][ 0/32]	Time  0.683 ( 0.683)	Data  0.007 ( 0.007)	Loss 5.5567e-02 (5.5567e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [159][16/32]	Time  0.687 ( 0.687)	Data  0.006 ( 0.006)	Loss 5.6577e-02 (4.5406e-02)	Acc@1  97.27 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [159/200], lr: 0.000005, acc: 98.7250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [160][ 0/32]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 4.3644e-02 (4.3644e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [160][16/32]	Time  0.682 ( 0.689)	Data  0.005 ( 0.006)	Loss 6.4337e-02 (4.6932e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [160/200], lr: 0.000005, acc: 98.6875, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [161][ 0/32]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 4.7156e-02 (4.7156e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [161][16/32]	Time  0.685 ( 0.690)	Data  0.006 ( 0.006)	Loss 6.0901e-02 (4.8330e-02)	Acc@1  97.66 ( 98.62)	Acc@5 100.00 (100.00)
Test Epoch: [161/200], lr: 0.000005, acc: 98.6250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [162][ 0/32]	Time  0.688 ( 0.688)	Data  0.007 ( 0.007)	Loss 4.9508e-02 (4.9508e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [162][16/32]	Time  0.675 ( 0.689)	Data  0.005 ( 0.006)	Loss 4.5594e-02 (4.6549e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [162/200], lr: 0.000005, acc: 98.5750, best: 98.7625
Epoch: [163][ 0/32]	Time  0.695 ( 0.695)	Data  0.007 ( 0.007)	Loss 5.7950e-02 (5.7950e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [163][16/32]	Time  0.686 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.2223e-02 (4.3412e-02)	Acc@1  99.61 ( 98.78)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [163/200], lr: 0.000005, acc: 98.5750, best: 98.7625
Epoch: [164][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 5.1080e-02 (5.1080e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [164][16/32]	Time  0.687 ( 0.691)	Data  0.006 ( 0.006)	Loss 3.7122e-02 (4.7338e-02)	Acc@1  99.22 ( 98.60)	Acc@5 100.00 (100.00)
Test Epoch: [164/200], lr: 0.000005, acc: 98.6625, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [165][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 3.7720e-02 (3.7720e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [165][16/32]	Time  0.682 ( 0.689)	Data  0.006 ( 0.012)	Loss 4.7478e-02 (4.3063e-02)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 (100.00)
Test Epoch: [165/200], lr: 0.000005, acc: 98.5375, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [166][ 0/32]	Time  0.687 ( 0.687)	Data  0.006 ( 0.006)	Loss 5.0930e-02 (5.0930e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [166][16/32]	Time  0.687 ( 0.687)	Data  0.006 ( 0.012)	Loss 4.4256e-02 (4.0995e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 (100.00)
Test Epoch: [166/200], lr: 0.000005, acc: 98.7500, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [167][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.2437e-02 (4.2437e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [167][16/32]	Time  0.687 ( 0.688)	Data  0.007 ( 0.012)	Loss 4.4510e-02 (4.2197e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [167/200], lr: 0.000005, acc: 98.6500, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [168][ 0/32]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 5.5231e-02 (5.5231e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [168][16/32]	Time  0.698 ( 0.690)	Data  0.006 ( 0.006)	Loss 3.6315e-02 (4.4952e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [168/200], lr: 0.000005, acc: 98.6250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [169][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 4.6299e-02 (4.6299e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [169][16/32]	Time  0.686 ( 0.685)	Data  0.006 ( 0.012)	Loss 4.2411e-02 (4.5406e-02)	Acc@1  98.83 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [169/200], lr: 0.000005, acc: 98.7625, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [170][ 0/32]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 6.5854e-02 (6.5854e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [170][16/32]	Time  0.685 ( 0.692)	Data  0.006 ( 0.012)	Loss 3.5157e-02 (4.7815e-02)	Acc@1  98.83 ( 98.53)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [170/200], lr: 0.000005, acc: 98.6875, best: 98.7625
Epoch: [171][ 0/32]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 3.9659e-02 (3.9659e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [171][16/32]	Time  0.689 ( 0.687)	Data  0.007 ( 0.012)	Loss 5.2144e-02 (4.6127e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [171/200], lr: 0.000005, acc: 98.7250, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [172][ 0/32]	Time  0.676 ( 0.676)	Data  0.008 ( 0.008)	Loss 4.5435e-02 (4.5435e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [172][16/32]	Time  0.686 ( 0.691)	Data  0.007 ( 0.012)	Loss 5.3674e-02 (4.3542e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [172/200], lr: 0.000005, acc: 98.7500, best: 98.7625
Epoch: [173][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.8454e-02 (5.8454e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [173][16/32]	Time  0.680 ( 0.685)	Data  0.006 ( 0.011)	Loss 3.1822e-02 (4.6155e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Test Epoch: [173/200], lr: 0.000005, acc: 98.6500, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [174][ 0/32]	Time  0.674 ( 0.674)	Data  0.007 ( 0.007)	Loss 3.6040e-02 (3.6040e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [174][16/32]	Time  0.686 ( 0.688)	Data  0.006 ( 0.011)	Loss 5.8943e-02 (4.4477e-02)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [174/200], lr: 0.000005, acc: 98.7125, best: 98.7625
Epoch: [175][ 0/32]	Time  0.674 ( 0.674)	Data  0.008 ( 0.008)	Loss 4.4367e-02 (4.4367e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [175][16/32]	Time  0.682 ( 0.688)	Data  0.007 ( 0.012)	Loss 4.1282e-02 (4.5870e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 (100.00)
Test Epoch: [175/200], lr: 0.000005, acc: 98.7375, best: 98.7625
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [176][ 0/32]	Time  0.685 ( 0.685)	Data  0.006 ( 0.006)	Loss 5.4349e-02 (5.4349e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [176][16/32]	Time  0.683 ( 0.691)	Data  0.006 ( 0.011)	Loss 3.7068e-02 (4.5144e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [176/200], lr: 0.000005, acc: 98.9375, best: 98.9375
Epoch: [177][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 3.8479e-02 (3.8479e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [177][16/32]	Time  0.680 ( 0.691)	Data  0.006 ( 0.006)	Loss 4.5441e-02 (4.4601e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Test Epoch: [177/200], lr: 0.000005, acc: 98.7000, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [178][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.5034e-02 (4.5034e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [178][16/32]	Time  0.683 ( 0.689)	Data  0.006 ( 0.006)	Loss 7.1467e-02 (4.6453e-02)	Acc@1  98.05 ( 98.62)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [178/200], lr: 0.000005, acc: 98.7750, best: 98.9375
Epoch: [179][ 0/32]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 4.3947e-02 (4.3947e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [179][16/32]	Time  0.681 ( 0.688)	Data  0.006 ( 0.006)	Loss 4.1126e-02 (4.2453e-02)	Acc@1  98.83 ( 98.87)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [179/200], lr: 0.000005, acc: 98.7250, best: 98.9375
Epoch: [180][ 0/32]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 3.5925e-02 (3.5925e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [180][16/32]	Time  0.687 ( 0.689)	Data  0.006 ( 0.006)	Loss 3.7417e-02 (4.5698e-02)	Acc@1  99.22 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [180/200], lr: 0.000005, acc: 98.6875, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [181][ 0/32]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 3.3993e-02 (3.3993e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [181][16/32]	Time  0.686 ( 0.690)	Data  0.006 ( 0.006)	Loss 2.9814e-02 (4.8785e-02)	Acc@1  99.22 ( 98.41)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [181/200], lr: 0.000005, acc: 98.6875, best: 98.9375
Epoch: [182][ 0/32]	Time  0.683 ( 0.683)	Data  0.006 ( 0.006)	Loss 5.4920e-02 (5.4920e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [182][16/32]	Time  0.682 ( 0.691)	Data  0.006 ( 0.006)	Loss 5.7467e-02 (4.4788e-02)	Acc@1  98.44 ( 98.60)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [182/200], lr: 0.000005, acc: 98.6000, best: 98.9375
Epoch: [183][ 0/32]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 6.3081e-02 (6.3081e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [183][16/32]	Time  0.684 ( 0.688)	Data  0.006 ( 0.006)	Loss 5.1355e-02 (4.9033e-02)	Acc@1  98.83 ( 98.51)	Acc@5 100.00 (100.00)
Test Epoch: [183/200], lr: 0.000005, acc: 98.6500, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [184][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 3.9948e-02 (3.9948e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [184][16/32]	Time  0.682 ( 0.685)	Data  0.006 ( 0.006)	Loss 5.9927e-02 (4.4827e-02)	Acc@1  98.05 ( 98.69)	Acc@5 100.00 (100.00)
Test Epoch: [184/200], lr: 0.000005, acc: 98.7125, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [185][ 0/32]	Time  0.691 ( 0.691)	Data  0.006 ( 0.006)	Loss 4.1608e-02 (4.1608e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [185][16/32]	Time  0.772 ( 0.686)	Data  0.006 ( 0.006)	Loss 5.4209e-02 (4.4167e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [185/200], lr: 0.000005, acc: 98.6375, best: 98.9375
Epoch: [186][ 0/32]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 5.3992e-02 (5.3992e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [186][16/32]	Time  0.683 ( 0.689)	Data  0.006 ( 0.006)	Loss 3.6391e-02 (4.5087e-02)	Acc@1  99.22 ( 98.69)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [186/200], lr: 0.000005, acc: 98.8125, best: 98.9375
Epoch: [187][ 0/32]	Time  0.680 ( 0.680)	Data  0.007 ( 0.007)	Loss 6.4490e-02 (6.4490e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [187][16/32]	Time  0.679 ( 0.682)	Data  0.006 ( 0.006)	Loss 3.4598e-02 (4.6807e-02)	Acc@1  99.22 ( 98.76)	Acc@5 100.00 (100.00)
Test Epoch: [187/200], lr: 0.000005, acc: 98.7125, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [188][ 0/32]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 5.3363e-02 (5.3363e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [188][16/32]	Time  0.680 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.6137e-02 (4.8714e-02)	Acc@1  99.22 ( 98.60)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [188/200], lr: 0.000005, acc: 98.5500, best: 98.9375
Epoch: [189][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 3.2155e-02 (3.2155e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [189][16/32]	Time  0.684 ( 0.684)	Data  0.006 ( 0.006)	Loss 5.2913e-02 (4.6044e-02)	Acc@1  98.05 ( 98.60)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [189/200], lr: 0.000005, acc: 98.7500, best: 98.9375
Epoch: [190][ 0/32]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 3.5350e-02 (3.5350e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [190][16/32]	Time  0.680 ( 0.682)	Data  0.006 ( 0.006)	Loss 5.6374e-02 (4.5529e-02)	Acc@1  98.05 ( 98.81)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [190/200], lr: 0.000005, acc: 98.5250, best: 98.9375
Epoch: [191][ 0/32]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 2.8697e-02 (2.8697e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [191][16/32]	Time  0.680 ( 0.681)	Data  0.006 ( 0.006)	Loss 4.7790e-02 (4.1059e-02)	Acc@1  98.83 ( 98.99)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [191/200], lr: 0.000005, acc: 98.6250, best: 98.9375
Epoch: [192][ 0/32]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 4.9076e-02 (4.9076e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [192][16/32]	Time  0.683 ( 0.685)	Data  0.006 ( 0.006)	Loss 5.3249e-02 (4.6783e-02)	Acc@1  98.05 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [192/200], lr: 0.000005, acc: 98.8000, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [193][ 0/32]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 3.8357e-02 (3.8357e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [193][16/32]	Time  0.683 ( 0.683)	Data  0.006 ( 0.006)	Loss 2.5497e-02 (4.2785e-02)	Acc@1  99.22 ( 98.90)	Acc@5 100.00 (100.00)
Test Epoch: [193/200], lr: 0.000005, acc: 98.7000, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [194][ 0/32]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.4366e-02 (5.4366e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [194][16/32]	Time  0.685 ( 0.688)	Data  0.006 ( 0.006)	Loss 6.1096e-02 (4.6096e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 (100.00)
Test Epoch: [194/200], lr: 0.000005, acc: 98.7125, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [195][ 0/32]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 3.6776e-02 (3.6776e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [195][16/32]	Time  0.691 ( 0.683)	Data  0.007 ( 0.006)	Loss 6.3193e-02 (4.5345e-02)	Acc@1  97.66 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [195/200], lr: 0.000005, acc: 98.7500, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [196][ 0/32]	Time  0.685 ( 0.685)	Data  0.007 ( 0.007)	Loss 3.4212e-02 (3.4212e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [196][16/32]	Time  0.675 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.3458e-02 (4.5304e-02)	Acc@1  97.66 ( 98.83)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [196/200], lr: 0.000005, acc: 98.6750, best: 98.9375
Epoch: [197][ 0/32]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 4.9931e-02 (4.9931e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [197][16/32]	Time  0.680 ( 0.681)	Data  0.006 ( 0.006)	Loss 3.5113e-02 (4.3473e-02)	Acc@1  99.22 ( 98.83)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [197/200], lr: 0.000005, acc: 98.7375, best: 98.9375
Epoch: [198][ 0/32]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.3801e-02 (4.3801e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [198][16/32]	Time  0.689 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.0570e-02 (4.8999e-02)	Acc@1  99.22 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [198/200], lr: 0.000005, acc: 98.5625, best: 98.9375
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [199][ 0/32]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.6562e-02 (5.6562e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [199][16/32]	Time  0.680 ( 0.689)	Data  0.006 ( 0.012)	Loss 6.8918e-02 (4.6762e-02)	Acc@1  97.66 ( 98.64)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:288: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:289: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [199/200], lr: 0.000005, acc: 98.7375, best: 98.9375

Process finished with exit code 0
