D:\Apps\Anaconda\envs\SNN\python.exe D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py 
Attributes shape: (8000, 201)
Labels shape: (8000,)
beta init from -0.50 and 0.50
+-------------------------+------------+
|         Modules         | Parameters |
+-------------------------+------------+
|    features.0.weight    |     64     |
|     features.0.bias     |     64     |
| features.1.decay_factor |     2      |
|    features.2.weight    |   16384    |
|     features.2.bias     |    256     |
| features.3.decay_factor |     2      |
|    features.4.weight    |   65536    |
|     features.4.bias     |    256     |
| features.5.decay_factor |     2      |
|    features.6.weight    |    2560    |
|     features.6.bias     |     10     |
+-------------------------+------------+
Total Trainable Params: 85136
Epoch: [0][ 0/25]	Time  2.072 ( 2.072)	Data  0.062 ( 0.062)	Loss 1.0568e+01 (1.0568e+01)	Acc@1  10.16 ( 10.16)	Acc@5  46.09 ( 46.09)
Epoch: [0][12/25]	Time  0.752 ( 0.798)	Data  0.007 ( 0.011)	Loss 3.8104e+00 (6.1587e+00)	Acc@1  20.31 ( 14.57)	Acc@5  71.48 ( 55.29)
Epoch: [0][24/25]	Time  0.656 ( 0.762)	Data  0.006 ( 0.008)	Loss 2.6082e+00 (4.5309e+00)	Acc@1  30.08 ( 20.55)	Acc@5  75.78 ( 66.83)
Test Epoch: [0/200], lr: 0.000500, acc: 28.3750, best: 28.3750
Epoch: [1][ 0/25]	Time  0.662 ( 0.662)	Data  0.008 ( 0.008)	Loss 2.5234e+00 (2.5234e+00)	Acc@1  30.08 ( 30.08)	Acc@5  82.81 ( 82.81)
Epoch: [1][12/25]	Time  0.672 ( 0.732)	Data  0.006 ( 0.006)	Loss 1.8549e+00 (2.1765e+00)	Acc@1  41.02 ( 31.49)	Acc@5  86.72 ( 84.34)
Epoch: [1][24/25]	Time  0.666 ( 0.708)	Data  0.007 ( 0.006)	Loss 1.7064e+00 (2.0174e+00)	Acc@1  36.72 ( 33.36)	Acc@5  92.97 ( 86.55)
Test Epoch: [1/200], lr: 0.000500, acc: 38.1250, best: 38.1250
Epoch: [2][ 0/25]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 1.6645e+00 (1.6645e+00)	Acc@1  41.02 ( 41.02)	Acc@5  90.23 ( 90.23)
Epoch: [2][12/25]	Time  0.658 ( 0.681)	Data  0.006 ( 0.007)	Loss 1.5374e+00 (1.6448e+00)	Acc@1  48.83 ( 42.34)	Acc@5  92.58 ( 91.32)
Epoch: [2][24/25]	Time  0.658 ( 0.676)	Data  0.006 ( 0.007)	Loss 1.5530e+00 (1.5880e+00)	Acc@1  46.48 ( 43.39)	Acc@5  92.19 ( 92.58)
Test Epoch: [2/200], lr: 0.000500, acc: 45.0625, best: 45.0625
Epoch: [3][ 0/25]	Time  0.655 ( 0.655)	Data  0.006 ( 0.006)	Loss 1.5405e+00 (1.5405e+00)	Acc@1  40.62 ( 40.62)	Acc@5  95.70 ( 95.70)
Epoch: [3][12/25]	Time  0.700 ( 0.696)	Data  0.007 ( 0.006)	Loss 1.5017e+00 (1.4518e+00)	Acc@1  42.97 ( 46.69)	Acc@5  95.70 ( 95.40)
Epoch: [3][24/25]	Time  0.766 ( 0.694)	Data  0.006 ( 0.006)	Loss 1.3046e+00 (1.3943e+00)	Acc@1  51.17 ( 48.89)	Acc@5  96.88 ( 95.77)
Test Epoch: [3/200], lr: 0.000500, acc: 50.4375, best: 50.4375
Epoch: [4][ 0/25]	Time  0.657 ( 0.657)	Data  0.007 ( 0.007)	Loss 1.3182e+00 (1.3182e+00)	Acc@1  48.05 ( 48.05)	Acc@5  96.88 ( 96.88)
Epoch: [4][12/25]	Time  0.693 ( 0.689)	Data  0.006 ( 0.006)	Loss 1.1624e+00 (1.2956e+00)	Acc@1  53.52 ( 51.20)	Acc@5  98.83 ( 96.88)
Epoch: [4][24/25]	Time  0.662 ( 0.690)	Data  0.006 ( 0.006)	Loss 1.1236e+00 (1.2450e+00)	Acc@1  58.20 ( 53.11)	Acc@5  97.66 ( 97.34)
Test Epoch: [4/200], lr: 0.000500, acc: 54.1875, best: 54.1875
Epoch: [5][ 0/25]	Time  0.655 ( 0.655)	Data  0.007 ( 0.007)	Loss 1.1248e+00 (1.1248e+00)	Acc@1  58.20 ( 58.20)	Acc@5  98.44 ( 98.44)
Epoch: [5][12/25]	Time  0.655 ( 0.663)	Data  0.007 ( 0.006)	Loss 1.1567e+00 (1.1330e+00)	Acc@1  57.03 ( 56.49)	Acc@5  98.83 ( 98.32)
Epoch: [5][24/25]	Time  0.650 ( 0.682)	Data  0.006 ( 0.006)	Loss 1.0067e+00 (1.0981e+00)	Acc@1  58.98 ( 58.06)	Acc@5  98.05 ( 98.30)
Test Epoch: [5/200], lr: 0.000500, acc: 59.0625, best: 59.0625
Epoch: [6][ 0/25]	Time  0.647 ( 0.647)	Data  0.007 ( 0.007)	Loss 8.9687e-01 (8.9687e-01)	Acc@1  65.62 ( 65.62)	Acc@5  98.83 ( 98.83)
Epoch: [6][12/25]	Time  0.644 ( 0.653)	Data  0.006 ( 0.006)	Loss 1.0297e+00 (9.9460e-01)	Acc@1  58.98 ( 61.51)	Acc@5  98.83 ( 98.71)
Epoch: [6][24/25]	Time  0.642 ( 0.651)	Data  0.006 ( 0.006)	Loss 8.8630e-01 (9.8236e-01)	Acc@1  67.58 ( 62.03)	Acc@5  99.61 ( 98.86)
Test Epoch: [6/200], lr: 0.000500, acc: 63.4375, best: 63.4375
Epoch: [7][ 0/25]	Time  0.635 ( 0.635)	Data  0.007 ( 0.007)	Loss 1.0131e+00 (1.0131e+00)	Acc@1  58.98 ( 58.98)	Acc@5  98.83 ( 98.83)
Epoch: [7][12/25]	Time  0.651 ( 0.666)	Data  0.006 ( 0.006)	Loss 8.7871e-01 (8.9617e-01)	Acc@1  69.14 ( 65.47)	Acc@5  99.22 ( 99.04)
Epoch: [7][24/25]	Time  0.657 ( 0.664)	Data  0.006 ( 0.006)	Loss 8.0146e-01 (9.0137e-01)	Acc@1  66.41 ( 65.53)	Acc@5 100.00 ( 99.14)
Test Epoch: [7/200], lr: 0.000500, acc: 65.7500, best: 65.7500
Epoch: [8][ 0/25]	Time  0.633 ( 0.633)	Data  0.007 ( 0.007)	Loss 8.3887e-01 (8.3887e-01)	Acc@1  67.19 ( 67.19)	Acc@5 100.00 (100.00)
Epoch: [8][12/25]	Time  0.649 ( 0.657)	Data  0.006 ( 0.006)	Loss 7.8360e-01 (7.9395e-01)	Acc@1  68.75 ( 69.41)	Acc@5 100.00 ( 99.52)
Epoch: [8][24/25]	Time  0.655 ( 0.660)	Data  0.007 ( 0.006)	Loss 7.9223e-01 (8.0791e-01)	Acc@1  70.31 ( 69.39)	Acc@5  99.61 ( 99.41)
Test Epoch: [8/200], lr: 0.000500, acc: 68.0000, best: 68.0000
Epoch: [9][ 0/25]	Time  0.624 ( 0.624)	Data  0.006 ( 0.006)	Loss 6.9872e-01 (6.9872e-01)	Acc@1  73.05 ( 73.05)	Acc@5  99.22 ( 99.22)
Epoch: [9][12/25]	Time  0.645 ( 0.655)	Data  0.006 ( 0.006)	Loss 6.9678e-01 (7.3485e-01)	Acc@1  77.34 ( 72.57)	Acc@5  99.22 ( 99.49)
Epoch: [9][24/25]	Time  0.664 ( 0.663)	Data  0.006 ( 0.007)	Loss 6.8608e-01 (7.2754e-01)	Acc@1  74.61 ( 72.55)	Acc@5  99.61 ( 99.55)
Test Epoch: [9/200], lr: 0.000500, acc: 73.3125, best: 73.3125
Epoch: [10][ 0/25]	Time  0.636 ( 0.636)	Data  0.006 ( 0.006)	Loss 7.2557e-01 (7.2557e-01)	Acc@1  69.92 ( 69.92)	Acc@5  99.22 ( 99.22)
Epoch: [10][12/25]	Time  0.646 ( 0.649)	Data  0.007 ( 0.006)	Loss 6.3101e-01 (6.9260e-01)	Acc@1  77.34 ( 73.77)	Acc@5  98.83 ( 99.49)
Epoch: [10][24/25]	Time  0.655 ( 0.656)	Data  0.006 ( 0.006)	Loss 5.9751e-01 (6.7887e-01)	Acc@1  78.52 ( 74.23)	Acc@5  98.83 ( 99.59)
Test Epoch: [10/200], lr: 0.000500, acc: 73.2500, best: 73.3125
Epoch: [11][ 0/25]	Time  0.644 ( 0.644)	Data  0.006 ( 0.006)	Loss 7.0772e-01 (7.0772e-01)	Acc@1  77.73 ( 77.73)	Acc@5  99.22 ( 99.22)
Epoch: [11][12/25]	Time  0.749 ( 0.677)	Data  0.007 ( 0.006)	Loss 6.2938e-01 (6.4333e-01)	Acc@1  75.39 ( 75.93)	Acc@5  99.61 ( 99.67)
Epoch: [11][24/25]	Time  0.649 ( 0.665)	Data  0.006 ( 0.006)	Loss 6.7159e-01 (6.2786e-01)	Acc@1  74.61 ( 76.50)	Acc@5 100.00 ( 99.70)
Test Epoch: [11/200], lr: 0.000500, acc: 75.3750, best: 75.3750
Epoch: [12][ 0/25]	Time  0.637 ( 0.637)	Data  0.007 ( 0.007)	Loss 4.9939e-01 (4.9939e-01)	Acc@1  82.03 ( 82.03)	Acc@5  99.61 ( 99.61)
Epoch: [12][12/25]	Time  0.643 ( 0.658)	Data  0.006 ( 0.007)	Loss 5.9480e-01 (5.6181e-01)	Acc@1  78.12 ( 78.85)	Acc@5 100.00 ( 99.88)
Epoch: [12][24/25]	Time  0.642 ( 0.659)	Data  0.006 ( 0.007)	Loss 5.2611e-01 (5.4661e-01)	Acc@1  81.64 ( 79.81)	Acc@5  99.61 ( 99.80)
Test Epoch: [12/200], lr: 0.000500, acc: 79.4375, best: 79.4375
Epoch: [13][ 0/25]	Time  0.647 ( 0.647)	Data  0.008 ( 0.008)	Loss 5.1654e-01 (5.1654e-01)	Acc@1  82.81 ( 82.81)	Acc@5 100.00 (100.00)
Epoch: [13][12/25]	Time  0.647 ( 0.665)	Data  0.006 ( 0.006)	Loss 5.1968e-01 (5.1021e-01)	Acc@1  82.81 ( 82.12)	Acc@5  99.61 ( 99.82)
Epoch: [13][24/25]	Time  0.655 ( 0.658)	Data  0.007 ( 0.006)	Loss 5.3666e-01 (5.0605e-01)	Acc@1  79.30 ( 81.92)	Acc@5 100.00 ( 99.77)
Test Epoch: [13/200], lr: 0.000500, acc: 81.9375, best: 81.9375
Epoch: [14][ 0/25]	Time  0.724 ( 0.724)	Data  0.006 ( 0.006)	Loss 5.2027e-01 (5.2027e-01)	Acc@1  81.25 ( 81.25)	Acc@5  99.22 ( 99.22)
Epoch: [14][12/25]	Time  0.644 ( 0.658)	Data  0.006 ( 0.006)	Loss 4.1615e-01 (4.6097e-01)	Acc@1  84.77 ( 83.38)	Acc@5 100.00 ( 99.88)
Epoch: [14][24/25]	Time  0.661 ( 0.662)	Data  0.006 ( 0.006)	Loss 4.3082e-01 (4.6146e-01)	Acc@1  87.11 ( 83.08)	Acc@5 100.00 ( 99.84)
Test Epoch: [14/200], lr: 0.000500, acc: 81.0000, best: 81.9375
Epoch: [15][ 0/25]	Time  0.705 ( 0.705)	Data  0.007 ( 0.007)	Loss 4.0174e-01 (4.0174e-01)	Acc@1  87.11 ( 87.11)	Acc@5 100.00 (100.00)
Epoch: [15][12/25]	Time  0.647 ( 0.666)	Data  0.006 ( 0.006)	Loss 3.9680e-01 (4.3309e-01)	Acc@1  86.72 ( 84.62)	Acc@5  99.61 ( 99.88)
Epoch: [15][24/25]	Time  0.644 ( 0.663)	Data  0.006 ( 0.006)	Loss 4.2241e-01 (4.3105e-01)	Acc@1  85.94 ( 84.61)	Acc@5 100.00 ( 99.89)
Test Epoch: [15/200], lr: 0.000500, acc: 83.8125, best: 83.8125
Epoch: [16][ 0/25]	Time  0.634 ( 0.634)	Data  0.007 ( 0.007)	Loss 4.2188e-01 (4.2188e-01)	Acc@1  87.50 ( 87.50)	Acc@5  99.61 ( 99.61)
Epoch: [16][12/25]	Time  0.649 ( 0.653)	Data  0.006 ( 0.006)	Loss 3.5785e-01 (4.0707e-01)	Acc@1  85.55 ( 86.06)	Acc@5 100.00 ( 99.85)
Epoch: [16][24/25]	Time  0.674 ( 0.664)	Data  0.007 ( 0.006)	Loss 3.6862e-01 (4.1350e-01)	Acc@1  85.55 ( 85.73)	Acc@5 100.00 ( 99.91)
Test Epoch: [16/200], lr: 0.000500, acc: 83.4375, best: 83.8125
Epoch: [17][ 0/25]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 3.6952e-01 (3.6952e-01)	Acc@1  85.94 ( 85.94)	Acc@5 100.00 (100.00)
Epoch: [17][12/25]	Time  0.673 ( 0.661)	Data  0.005 ( 0.006)	Loss 3.5625e-01 (3.8139e-01)	Acc@1  85.94 ( 85.91)	Acc@5 100.00 ( 99.97)
Epoch: [17][24/25]	Time  0.740 ( 0.660)	Data  0.006 ( 0.006)	Loss 4.8598e-01 (3.8222e-01)	Acc@1  82.42 ( 85.92)	Acc@5 100.00 ( 99.95)
Test Epoch: [17/200], lr: 0.000500, acc: 86.0625, best: 86.0625
Epoch: [18][ 0/25]	Time  0.656 ( 0.656)	Data  0.006 ( 0.006)	Loss 3.2568e-01 (3.2568e-01)	Acc@1  89.45 ( 89.45)	Acc@5 100.00 (100.00)
Epoch: [18][12/25]	Time  0.650 ( 0.662)	Data  0.006 ( 0.006)	Loss 3.9677e-01 (3.8009e-01)	Acc@1  85.55 ( 86.54)	Acc@5 100.00 (100.00)
Epoch: [18][24/25]	Time  0.643 ( 0.666)	Data  0.007 ( 0.006)	Loss 3.3328e-01 (3.6991e-01)	Acc@1  89.45 ( 86.95)	Acc@5 100.00 (100.00)
Test Epoch: [18/200], lr: 0.000500, acc: 86.9375, best: 86.9375
Epoch: [19][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 4.1003e-01 (4.1003e-01)	Acc@1  83.20 ( 83.20)	Acc@5  99.61 ( 99.61)
Epoch: [19][12/25]	Time  0.662 ( 0.667)	Data  0.006 ( 0.006)	Loss 3.2534e-01 (3.4766e-01)	Acc@1  87.89 ( 88.01)	Acc@5 100.00 ( 99.91)
Epoch: [19][24/25]	Time  0.673 ( 0.662)	Data  0.006 ( 0.006)	Loss 3.2723e-01 (3.3489e-01)	Acc@1  91.02 ( 88.44)	Acc@5  99.61 ( 99.94)
Test Epoch: [19/200], lr: 0.000500, acc: 86.0000, best: 86.9375
Epoch: [20][ 0/25]	Time  0.639 ( 0.639)	Data  0.007 ( 0.007)	Loss 3.0783e-01 (3.0783e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [20][12/25]	Time  0.655 ( 0.650)	Data  0.006 ( 0.006)	Loss 3.9870e-01 (2.9577e-01)	Acc@1  83.59 ( 89.42)	Acc@5  99.22 ( 99.94)
Epoch: [20][24/25]	Time  0.649 ( 0.664)	Data  0.006 ( 0.006)	Loss 3.3543e-01 (2.8722e-01)	Acc@1  88.67 ( 89.77)	Acc@5 100.00 ( 99.97)
Test Epoch: [20/200], lr: 0.000500, acc: 86.9375, best: 86.9375
Epoch: [21][ 0/25]	Time  0.653 ( 0.653)	Data  0.007 ( 0.007)	Loss 2.5027e-01 (2.5027e-01)	Acc@1  91.80 ( 91.80)	Acc@5 100.00 (100.00)
Epoch: [21][12/25]	Time  0.644 ( 0.649)	Data  0.006 ( 0.006)	Loss 3.2238e-01 (2.8664e-01)	Acc@1  88.67 ( 89.96)	Acc@5 100.00 (100.00)
Epoch: [21][24/25]	Time  0.654 ( 0.658)	Data  0.006 ( 0.006)	Loss 2.9618e-01 (2.8947e-01)	Acc@1  89.45 ( 90.14)	Acc@5 100.00 (100.00)
Test Epoch: [21/200], lr: 0.000500, acc: 86.6250, best: 86.9375
Epoch: [22][ 0/25]	Time  0.631 ( 0.631)	Data  0.007 ( 0.007)	Loss 3.4608e-01 (3.4608e-01)	Acc@1  86.72 ( 86.72)	Acc@5 100.00 (100.00)
Epoch: [22][12/25]	Time  0.699 ( 0.671)	Data  0.007 ( 0.006)	Loss 2.2738e-01 (2.8110e-01)	Acc@1  91.02 ( 89.93)	Acc@5 100.00 (100.00)
Epoch: [22][24/25]	Time  0.669 ( 0.668)	Data  0.006 ( 0.006)	Loss 2.1322e-01 (2.7668e-01)	Acc@1  92.19 ( 90.39)	Acc@5 100.00 ( 99.98)
Test Epoch: [22/200], lr: 0.000500, acc: 88.7500, best: 88.7500
Epoch: [23][ 0/25]	Time  0.670 ( 0.670)	Data  0.007 ( 0.007)	Loss 2.8613e-01 (2.8613e-01)	Acc@1  90.62 ( 90.62)	Acc@5  99.61 ( 99.61)
Epoch: [23][12/25]	Time  0.670 ( 0.679)	Data  0.006 ( 0.006)	Loss 2.6704e-01 (2.6047e-01)	Acc@1  89.06 ( 91.05)	Acc@5 100.00 ( 99.94)
Epoch: [23][24/25]	Time  0.662 ( 0.678)	Data  0.006 ( 0.006)	Loss 2.0972e-01 (2.5201e-01)	Acc@1  92.19 ( 91.17)	Acc@5 100.00 ( 99.97)
Test Epoch: [23/200], lr: 0.000500, acc: 89.2500, best: 89.2500
Epoch: [24][ 0/25]	Time  0.648 ( 0.648)	Data  0.006 ( 0.006)	Loss 2.9075e-01 (2.9075e-01)	Acc@1  89.45 ( 89.45)	Acc@5 100.00 (100.00)
Epoch: [24][12/25]	Time  0.646 ( 0.677)	Data  0.006 ( 0.006)	Loss 1.9266e-01 (2.3682e-01)	Acc@1  94.14 ( 91.65)	Acc@5 100.00 ( 99.97)
Epoch: [24][24/25]	Time  0.730 ( 0.666)	Data  0.006 ( 0.006)	Loss 2.8323e-01 (2.4533e-01)	Acc@1  91.02 ( 91.34)	Acc@5 100.00 ( 99.97)
Test Epoch: [24/200], lr: 0.000500, acc: 88.0000, best: 89.2500
Epoch: [25][ 0/25]	Time  0.633 ( 0.633)	Data  0.006 ( 0.006)	Loss 2.3227e-01 (2.3227e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [25][12/25]	Time  0.647 ( 0.646)	Data  0.006 ( 0.006)	Loss 2.3486e-01 (2.4350e-01)	Acc@1  92.58 ( 91.95)	Acc@5 100.00 ( 99.97)
Epoch: [25][24/25]	Time  0.645 ( 0.652)	Data  0.006 ( 0.006)	Loss 1.8864e-01 (2.3371e-01)	Acc@1  91.02 ( 92.00)	Acc@5 100.00 ( 99.97)
Test Epoch: [25/200], lr: 0.000500, acc: 91.0000, best: 91.0000
Epoch: [26][ 0/25]	Time  0.650 ( 0.650)	Data  0.007 ( 0.007)	Loss 2.0839e-01 (2.0839e-01)	Acc@1  92.97 ( 92.97)	Acc@5  99.61 ( 99.61)
Epoch: [26][12/25]	Time  0.646 ( 0.664)	Data  0.006 ( 0.006)	Loss 2.0898e-01 (2.2885e-01)	Acc@1  92.58 ( 91.98)	Acc@5 100.00 ( 99.97)
Epoch: [26][24/25]	Time  0.639 ( 0.660)	Data  0.006 ( 0.006)	Loss 2.1589e-01 (2.1746e-01)	Acc@1  92.97 ( 92.45)	Acc@5  99.61 ( 99.97)
Test Epoch: [26/200], lr: 0.000500, acc: 91.3750, best: 91.3750
Epoch: [27][ 0/25]	Time  0.645 ( 0.645)	Data  0.006 ( 0.006)	Loss 2.0819e-01 (2.0819e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [27][12/25]	Time  0.662 ( 0.651)	Data  0.007 ( 0.006)	Loss 1.8293e-01 (1.9223e-01)	Acc@1  94.53 ( 93.48)	Acc@5 100.00 ( 99.97)
Epoch: [27][24/25]	Time  0.650 ( 0.659)	Data  0.007 ( 0.006)	Loss 2.0143e-01 (1.9645e-01)	Acc@1  92.97 ( 93.38)	Acc@5 100.00 ( 99.97)
Test Epoch: [27/200], lr: 0.000500, acc: 91.8125, best: 91.8125
Epoch: [28][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 1.7669e-01 (1.7669e-01)	Acc@1  92.97 ( 92.97)	Acc@5 100.00 (100.00)
Epoch: [28][12/25]	Time  0.646 ( 0.665)	Data  0.006 ( 0.006)	Loss 2.2145e-01 (1.7839e-01)	Acc@1  92.58 ( 93.60)	Acc@5 100.00 (100.00)
Epoch: [28][24/25]	Time  0.644 ( 0.656)	Data  0.006 ( 0.006)	Loss 1.9878e-01 (1.8850e-01)	Acc@1  94.92 ( 93.59)	Acc@5 100.00 ( 99.98)
Test Epoch: [28/200], lr: 0.000500, acc: 91.4375, best: 91.8125
Epoch: [29][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 1.6933e-01 (1.6933e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [29][12/25]	Time  0.641 ( 0.668)	Data  0.006 ( 0.006)	Loss 2.4003e-01 (1.8084e-01)	Acc@1  92.97 ( 94.26)	Acc@5 100.00 ( 99.97)
Epoch: [29][24/25]	Time  0.699 ( 0.661)	Data  0.006 ( 0.006)	Loss 1.7514e-01 (1.8355e-01)	Acc@1  92.58 ( 93.80)	Acc@5 100.00 ( 99.98)
Test Epoch: [29/200], lr: 0.000500, acc: 92.0625, best: 92.0625
Epoch: [30][ 0/25]	Time  0.685 ( 0.685)	Data  0.006 ( 0.006)	Loss 1.6155e-01 (1.6155e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [30][12/25]	Time  0.637 ( 0.667)	Data  0.006 ( 0.006)	Loss 1.0691e-01 (1.8691e-01)	Acc@1  98.44 ( 93.54)	Acc@5 100.00 ( 99.97)
Epoch: [30][24/25]	Time  0.648 ( 0.664)	Data  0.006 ( 0.006)	Loss 1.8955e-01 (1.8108e-01)	Acc@1  91.80 ( 93.88)	Acc@5 100.00 ( 99.97)
Test Epoch: [30/200], lr: 0.000500, acc: 92.9375, best: 92.9375
Epoch: [31][ 0/25]	Time  0.634 ( 0.634)	Data  0.006 ( 0.006)	Loss 2.0539e-01 (2.0539e-01)	Acc@1  91.80 ( 91.80)	Acc@5 100.00 (100.00)
Epoch: [31][12/25]	Time  0.654 ( 0.650)	Data  0.006 ( 0.006)	Loss 2.2330e-01 (1.9227e-01)	Acc@1  91.02 ( 93.06)	Acc@5 100.00 (100.00)
Epoch: [31][24/25]	Time  0.648 ( 0.662)	Data  0.006 ( 0.007)	Loss 1.8066e-01 (1.7751e-01)	Acc@1  93.36 ( 93.77)	Acc@5 100.00 (100.00)
Test Epoch: [31/200], lr: 0.000500, acc: 91.8125, best: 92.9375
Epoch: [32][ 0/25]	Time  0.647 ( 0.647)	Data  0.006 ( 0.006)	Loss 1.5809e-01 (1.5809e-01)	Acc@1  94.14 ( 94.14)	Acc@5 100.00 (100.00)
Epoch: [32][12/25]	Time  0.642 ( 0.649)	Data  0.007 ( 0.006)	Loss 2.0427e-01 (1.7123e-01)	Acc@1  92.19 ( 94.26)	Acc@5 100.00 (100.00)
Epoch: [32][24/25]	Time  0.641 ( 0.652)	Data  0.007 ( 0.006)	Loss 1.5572e-01 (1.7159e-01)	Acc@1  95.31 ( 94.34)	Acc@5 100.00 (100.00)
Test Epoch: [32/200], lr: 0.000500, acc: 92.7500, best: 92.9375
Epoch: [33][ 0/25]	Time  0.636 ( 0.636)	Data  0.007 ( 0.007)	Loss 1.2124e-01 (1.2124e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [33][12/25]	Time  0.696 ( 0.673)	Data  0.006 ( 0.006)	Loss 2.1424e-01 (1.5187e-01)	Acc@1  94.53 ( 95.25)	Acc@5 100.00 (100.00)
Epoch: [33][24/25]	Time  0.644 ( 0.671)	Data  0.006 ( 0.006)	Loss 1.1452e-01 (1.5318e-01)	Acc@1  96.88 ( 95.19)	Acc@5 100.00 (100.00)
Test Epoch: [33/200], lr: 0.000500, acc: 93.3125, best: 93.3125
Epoch: [34][ 0/25]	Time  0.658 ( 0.658)	Data  0.007 ( 0.007)	Loss 1.6706e-01 (1.6706e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [34][12/25]	Time  0.649 ( 0.659)	Data  0.006 ( 0.006)	Loss 1.4078e-01 (1.4421e-01)	Acc@1  96.09 ( 95.55)	Acc@5 100.00 (100.00)
Epoch: [34][24/25]	Time  0.646 ( 0.660)	Data  0.006 ( 0.006)	Loss 1.3799e-01 (1.4568e-01)	Acc@1  94.53 ( 95.20)	Acc@5 100.00 (100.00)
Test Epoch: [34/200], lr: 0.000500, acc: 91.7500, best: 93.3125
Epoch: [35][ 0/25]	Time  0.644 ( 0.644)	Data  0.007 ( 0.007)	Loss 1.7809e-01 (1.7809e-01)	Acc@1  94.14 ( 94.14)	Acc@5 100.00 (100.00)
Epoch: [35][12/25]	Time  0.666 ( 0.658)	Data  0.006 ( 0.006)	Loss 1.5710e-01 (1.3924e-01)	Acc@1  93.75 ( 95.01)	Acc@5 100.00 (100.00)
Epoch: [35][24/25]	Time  0.651 ( 0.662)	Data  0.006 ( 0.006)	Loss 1.5768e-01 (1.4001e-01)	Acc@1  95.31 ( 95.28)	Acc@5 100.00 (100.00)
Test Epoch: [35/200], lr: 0.000500, acc: 93.3750, best: 93.3750
Epoch: [36][ 0/25]	Time  0.650 ( 0.650)	Data  0.006 ( 0.006)	Loss 1.4027e-01 (1.4027e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [36][12/25]	Time  0.655 ( 0.664)	Data  0.006 ( 0.006)	Loss 1.4681e-01 (1.4217e-01)	Acc@1  94.53 ( 95.10)	Acc@5 100.00 (100.00)
Epoch: [36][24/25]	Time  0.650 ( 0.659)	Data  0.008 ( 0.006)	Loss 1.1865e-01 (1.4169e-01)	Acc@1  97.27 ( 95.17)	Acc@5 100.00 (100.00)
Test Epoch: [36/200], lr: 0.000500, acc: 93.6875, best: 93.6875
Epoch: [37][ 0/25]	Time  0.638 ( 0.638)	Data  0.007 ( 0.007)	Loss 9.7531e-02 (9.7531e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [37][12/25]	Time  0.649 ( 0.657)	Data  0.006 ( 0.006)	Loss 1.6096e-01 (1.3150e-01)	Acc@1  93.75 ( 95.61)	Acc@5 100.00 (100.00)
Epoch: [37][24/25]	Time  0.649 ( 0.663)	Data  0.007 ( 0.006)	Loss 1.4046e-01 (1.3792e-01)	Acc@1  94.92 ( 95.36)	Acc@5 100.00 (100.00)
Test Epoch: [37/200], lr: 0.000500, acc: 93.9375, best: 93.9375
Epoch: [38][ 0/25]	Time  0.657 ( 0.657)	Data  0.006 ( 0.006)	Loss 1.4918e-01 (1.4918e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [38][12/25]	Time  0.646 ( 0.651)	Data  0.005 ( 0.006)	Loss 1.5912e-01 (1.4413e-01)	Acc@1  94.53 ( 95.34)	Acc@5 100.00 (100.00)
Epoch: [38][24/25]	Time  0.645 ( 0.658)	Data  0.006 ( 0.006)	Loss 1.1042e-01 (1.4176e-01)	Acc@1  96.48 ( 95.44)	Acc@5 100.00 (100.00)
Test Epoch: [38/200], lr: 0.000500, acc: 94.0000, best: 94.0000
Epoch: [39][ 0/25]	Time  0.629 ( 0.629)	Data  0.007 ( 0.007)	Loss 1.0096e-01 (1.0096e-01)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [39][12/25]	Time  0.735 ( 0.654)	Data  0.006 ( 0.006)	Loss 1.3623e-01 (1.4591e-01)	Acc@1  95.31 ( 94.98)	Acc@5 100.00 (100.00)
Epoch: [39][24/25]	Time  0.642 ( 0.654)	Data  0.006 ( 0.006)	Loss 1.1508e-01 (1.3891e-01)	Acc@1  96.09 ( 95.22)	Acc@5 100.00 ( 99.98)
Test Epoch: [39/200], lr: 0.000500, acc: 93.3750, best: 94.0000
Epoch: [40][ 0/25]	Time  0.633 ( 0.633)	Data  0.007 ( 0.007)	Loss 1.1840e-01 (1.1840e-01)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [40][12/25]	Time  0.647 ( 0.653)	Data  0.007 ( 0.006)	Loss 1.5223e-01 (1.4370e-01)	Acc@1  95.31 ( 94.89)	Acc@5 100.00 (100.00)
Epoch: [40][24/25]	Time  0.643 ( 0.652)	Data  0.006 ( 0.006)	Loss 9.6725e-02 (1.4502e-01)	Acc@1  96.48 ( 94.92)	Acc@5 100.00 ( 99.97)
Test Epoch: [40/200], lr: 0.000500, acc: 93.2500, best: 94.0000
Epoch: [41][ 0/25]	Time  0.634 ( 0.634)	Data  0.006 ( 0.006)	Loss 1.4317e-01 (1.4317e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [41][12/25]	Time  0.669 ( 0.675)	Data  0.006 ( 0.007)	Loss 1.5510e-01 (1.5554e-01)	Acc@1  93.36 ( 94.77)	Acc@5 100.00 (100.00)
Epoch: [41][24/25]	Time  0.656 ( 0.670)	Data  0.006 ( 0.007)	Loss 1.1683e-01 (1.4938e-01)	Acc@1  95.70 ( 95.08)	Acc@5 100.00 (100.00)
Test Epoch: [41/200], lr: 0.000500, acc: 92.5000, best: 94.0000
Epoch: [42][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 2.0258e-01 (2.0258e-01)	Acc@1  92.58 ( 92.58)	Acc@5 100.00 (100.00)
Epoch: [42][12/25]	Time  0.667 ( 0.671)	Data  0.006 ( 0.006)	Loss 9.3944e-02 (1.4012e-01)	Acc@1  96.48 ( 95.19)	Acc@5 100.00 (100.00)
Epoch: [42][24/25]	Time  0.667 ( 0.677)	Data  0.006 ( 0.006)	Loss 1.1150e-01 (1.3183e-01)	Acc@1  96.48 ( 95.58)	Acc@5 100.00 (100.00)
Test Epoch: [42/200], lr: 0.000500, acc: 94.3125, best: 94.3125
Epoch: [43][ 0/25]	Time  0.658 ( 0.658)	Data  0.007 ( 0.007)	Loss 7.9061e-02 (7.9061e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [43][12/25]	Time  0.667 ( 0.669)	Data  0.006 ( 0.006)	Loss 9.4598e-02 (1.1983e-01)	Acc@1  96.88 ( 96.18)	Acc@5 100.00 (100.00)
Epoch: [43][24/25]	Time  0.663 ( 0.674)	Data  0.006 ( 0.006)	Loss 1.2733e-01 (1.2163e-01)	Acc@1  95.70 ( 95.95)	Acc@5 100.00 (100.00)
Test Epoch: [43/200], lr: 0.000500, acc: 94.1250, best: 94.3125
Epoch: [44][ 0/25]	Time  0.751 ( 0.751)	Data  0.006 ( 0.006)	Loss 1.1254e-01 (1.1254e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [44][12/25]	Time  0.665 ( 0.673)	Data  0.006 ( 0.006)	Loss 8.9646e-02 (1.1713e-01)	Acc@1  98.05 ( 95.88)	Acc@5 100.00 (100.00)
Epoch: [44][24/25]	Time  0.674 ( 0.681)	Data  0.006 ( 0.006)	Loss 1.1434e-01 (1.1848e-01)	Acc@1  97.27 ( 95.91)	Acc@5 100.00 ( 99.98)
Test Epoch: [44/200], lr: 0.000500, acc: 93.9375, best: 94.3125
Epoch: [45][ 0/25]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 1.6265e-01 (1.6265e-01)	Acc@1  94.14 ( 94.14)	Acc@5 100.00 (100.00)
Epoch: [45][12/25]	Time  0.676 ( 0.688)	Data  0.006 ( 0.007)	Loss 1.1736e-01 (1.2561e-01)	Acc@1  96.48 ( 95.52)	Acc@5 100.00 (100.00)
Epoch: [45][24/25]	Time  0.669 ( 0.680)	Data  0.007 ( 0.007)	Loss 1.1901e-01 (1.2942e-01)	Acc@1  95.70 ( 95.36)	Acc@5 100.00 (100.00)
Test Epoch: [45/200], lr: 0.000500, acc: 93.9375, best: 94.3125
Epoch: [46][ 0/25]	Time  0.662 ( 0.662)	Data  0.006 ( 0.006)	Loss 1.1696e-01 (1.1696e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [46][12/25]	Time  0.664 ( 0.679)	Data  0.007 ( 0.006)	Loss 1.1766e-01 (1.0495e-01)	Acc@1  93.75 ( 96.12)	Acc@5 100.00 (100.00)
Epoch: [46][24/25]	Time  0.669 ( 0.680)	Data  0.006 ( 0.006)	Loss 1.2354e-01 (1.0789e-01)	Acc@1  96.09 ( 96.06)	Acc@5 100.00 (100.00)
Test Epoch: [46/200], lr: 0.000500, acc: 94.2500, best: 94.3125
Epoch: [47][ 0/25]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 1.0375e-01 (1.0375e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [47][12/25]	Time  0.675 ( 0.669)	Data  0.006 ( 0.006)	Loss 1.3471e-01 (1.0048e-01)	Acc@1  95.31 ( 96.54)	Acc@5 100.00 (100.00)
Epoch: [47][24/25]	Time  0.764 ( 0.680)	Data  0.006 ( 0.006)	Loss 9.5060e-02 (1.0289e-01)	Acc@1  96.48 ( 96.47)	Acc@5 100.00 (100.00)
Test Epoch: [47/200], lr: 0.000500, acc: 94.3125, best: 94.3125
Epoch: [48][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 1.1960e-01 (1.1960e-01)	Acc@1  95.70 ( 95.70)	Acc@5 100.00 (100.00)
Epoch: [48][12/25]	Time  0.666 ( 0.673)	Data  0.007 ( 0.006)	Loss 6.2547e-02 (1.1928e-01)	Acc@1  97.66 ( 95.73)	Acc@5 100.00 (100.00)
Epoch: [48][24/25]	Time  0.675 ( 0.676)	Data  0.006 ( 0.006)	Loss 1.7457e-01 (1.1812e-01)	Acc@1  92.97 ( 95.70)	Acc@5 100.00 (100.00)
Test Epoch: [48/200], lr: 0.000500, acc: 94.5625, best: 94.5625
Epoch: [49][ 0/25]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 8.5698e-02 (8.5698e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [49][12/25]	Time  0.805 ( 0.688)	Data  0.006 ( 0.006)	Loss 1.1036e-01 (1.0867e-01)	Acc@1  96.88 ( 96.33)	Acc@5 100.00 (100.00)
Epoch: [49][24/25]	Time  0.670 ( 0.680)	Data  0.006 ( 0.006)	Loss 1.2118e-01 (1.1385e-01)	Acc@1  96.48 ( 96.17)	Acc@5 100.00 (100.00)
Test Epoch: [49/200], lr: 0.000500, acc: 94.1875, best: 94.5625
Epoch: [50][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 8.5795e-02 (8.5795e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [50][12/25]	Time  0.668 ( 0.679)	Data  0.006 ( 0.007)	Loss 1.1150e-01 (9.5343e-02)	Acc@1  96.09 ( 96.91)	Acc@5 100.00 (100.00)
Epoch: [50][24/25]	Time  0.671 ( 0.679)	Data  0.006 ( 0.007)	Loss 1.1918e-01 (1.0249e-01)	Acc@1  96.48 ( 96.66)	Acc@5 100.00 (100.00)
Test Epoch: [50/200], lr: 0.000500, acc: 94.1250, best: 94.5625
Epoch: [51][ 0/25]	Time  0.659 ( 0.659)	Data  0.006 ( 0.006)	Loss 1.2575e-01 (1.2575e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [51][12/25]	Time  0.663 ( 0.676)	Data  0.007 ( 0.007)	Loss 1.2234e-01 (1.0744e-01)	Acc@1  96.48 ( 96.12)	Acc@5 100.00 (100.00)
Epoch: [51][24/25]	Time  0.660 ( 0.674)	Data  0.006 ( 0.006)	Loss 8.1323e-02 (1.0395e-01)	Acc@1  97.27 ( 96.36)	Acc@5 100.00 (100.00)
Test Epoch: [51/200], lr: 0.000500, acc: 94.0625, best: 94.5625
Epoch: [52][ 0/25]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 8.0673e-02 (8.0673e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [52][12/25]	Time  0.665 ( 0.683)	Data  0.006 ( 0.006)	Loss 6.4200e-02 (8.8162e-02)	Acc@1  98.05 ( 97.21)	Acc@5 100.00 (100.00)
Epoch: [52][24/25]	Time  0.675 ( 0.682)	Data  0.006 ( 0.006)	Loss 1.4753e-01 (9.2923e-02)	Acc@1  95.70 ( 96.98)	Acc@5 100.00 (100.00)
Test Epoch: [52/200], lr: 0.000500, acc: 94.4375, best: 94.5625
Epoch: [53][ 0/25]	Time  0.667 ( 0.667)	Data  0.007 ( 0.007)	Loss 9.9941e-02 (9.9941e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [53][12/25]	Time  0.668 ( 0.670)	Data  0.006 ( 0.006)	Loss 6.0346e-02 (8.3944e-02)	Acc@1  98.44 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][24/25]	Time  0.672 ( 0.680)	Data  0.007 ( 0.006)	Loss 8.0481e-02 (8.7400e-02)	Acc@1  97.66 ( 97.20)	Acc@5 100.00 (100.00)
Test Epoch: [53/200], lr: 0.000500, acc: 94.8750, best: 94.8750
Epoch: [54][ 0/25]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 1.1653e-01 (1.1653e-01)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [54][12/25]	Time  0.695 ( 0.679)	Data  0.006 ( 0.006)	Loss 1.1738e-01 (1.0078e-01)	Acc@1  96.09 ( 96.75)	Acc@5 100.00 (100.00)
Epoch: [54][24/25]	Time  0.762 ( 0.681)	Data  0.006 ( 0.006)	Loss 1.1945e-01 (9.6336e-02)	Acc@1  95.31 ( 96.70)	Acc@5 100.00 (100.00)
Test Epoch: [54/200], lr: 0.000500, acc: 94.6250, best: 94.8750
Epoch: [55][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 8.9262e-02 (8.9262e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [55][12/25]	Time  0.668 ( 0.679)	Data  0.006 ( 0.007)	Loss 1.1466e-01 (9.5589e-02)	Acc@1  96.09 ( 96.84)	Acc@5 100.00 (100.00)
Epoch: [55][24/25]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 8.7526e-02 (9.2521e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Test Epoch: [55/200], lr: 0.000500, acc: 94.5625, best: 94.8750
Epoch: [56][ 0/25]	Time  0.677 ( 0.677)	Data  0.007 ( 0.007)	Loss 1.0915e-01 (1.0915e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [56][12/25]	Time  0.670 ( 0.688)	Data  0.006 ( 0.006)	Loss 9.0161e-02 (8.7523e-02)	Acc@1  96.48 ( 97.00)	Acc@5 100.00 (100.00)
Epoch: [56][24/25]	Time  0.665 ( 0.680)	Data  0.006 ( 0.006)	Loss 6.4320e-02 (8.5098e-02)	Acc@1  98.05 ( 97.16)	Acc@5 100.00 (100.00)
Test Epoch: [56/200], lr: 0.000500, acc: 95.1250, best: 95.1250
Epoch: [57][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 8.0911e-02 (8.0911e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [57][12/25]	Time  0.672 ( 0.672)	Data  0.006 ( 0.007)	Loss 8.6418e-02 (7.7228e-02)	Acc@1  97.27 ( 97.51)	Acc@5 100.00 (100.00)
Epoch: [57][24/25]	Time  0.665 ( 0.679)	Data  0.007 ( 0.006)	Loss 1.2129e-01 (8.4276e-02)	Acc@1  94.92 ( 97.27)	Acc@5 100.00 (100.00)
Test Epoch: [57/200], lr: 0.000500, acc: 95.4375, best: 95.4375
Epoch: [58][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 5.9935e-02 (5.9935e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [58][12/25]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 8.2910e-02 (8.1800e-02)	Acc@1  96.88 ( 97.15)	Acc@5 100.00 (100.00)
Epoch: [58][24/25]	Time  0.667 ( 0.674)	Data  0.005 ( 0.006)	Loss 7.0241e-02 (8.1027e-02)	Acc@1  98.05 ( 97.25)	Acc@5 100.00 (100.00)
Test Epoch: [58/200], lr: 0.000500, acc: 95.1250, best: 95.4375
Epoch: [59][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 5.9046e-02 (5.9046e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [59][12/25]	Time  0.680 ( 0.688)	Data  0.006 ( 0.006)	Loss 7.0178e-02 (8.0043e-02)	Acc@1  97.66 ( 97.60)	Acc@5 100.00 (100.00)
Epoch: [59][24/25]	Time  0.664 ( 0.678)	Data  0.006 ( 0.006)	Loss 6.7250e-02 (8.1326e-02)	Acc@1  97.27 ( 97.45)	Acc@5 100.00 ( 99.98)
Test Epoch: [59/200], lr: 0.000500, acc: 94.1875, best: 95.4375
Epoch: [60][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 5.8446e-02 (5.8446e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [60][12/25]	Time  0.672 ( 0.680)	Data  0.006 ( 0.006)	Loss 9.9366e-02 (7.3269e-02)	Acc@1  96.09 ( 97.51)	Acc@5 100.00 (100.00)
Epoch: [60][24/25]	Time  0.674 ( 0.681)	Data  0.007 ( 0.006)	Loss 6.4189e-02 (6.8698e-02)	Acc@1  96.88 ( 97.62)	Acc@5 100.00 (100.00)
Test Epoch: [60/200], lr: 0.000050, acc: 95.8125, best: 95.8125
Epoch: [61][ 0/25]	Time  0.671 ( 0.671)	Data  0.007 ( 0.007)	Loss 5.2973e-02 (5.2973e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [61][12/25]	Time  0.680 ( 0.680)	Data  0.005 ( 0.006)	Loss 8.5833e-02 (6.9021e-02)	Acc@1  96.48 ( 97.87)	Acc@5 100.00 (100.00)
Epoch: [61][24/25]	Time  0.676 ( 0.678)	Data  0.007 ( 0.006)	Loss 5.8815e-02 (6.7296e-02)	Acc@1  98.83 ( 97.94)	Acc@5 100.00 (100.00)
Test Epoch: [61/200], lr: 0.000050, acc: 95.4375, best: 95.8125
Epoch: [62][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 6.9790e-02 (6.9790e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [62][12/25]	Time  0.674 ( 0.673)	Data  0.007 ( 0.006)	Loss 4.0688e-02 (6.1703e-02)	Acc@1  98.44 ( 97.90)	Acc@5 100.00 (100.00)
Epoch: [62][24/25]	Time  0.666 ( 0.674)	Data  0.006 ( 0.006)	Loss 8.7759e-02 (6.5281e-02)	Acc@1  97.27 ( 97.84)	Acc@5 100.00 (100.00)
Test Epoch: [62/200], lr: 0.000050, acc: 96.0000, best: 96.0000
Epoch: [63][ 0/25]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 9.1514e-02 (9.1514e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [63][12/25]	Time  0.672 ( 0.679)	Data  0.007 ( 0.006)	Loss 7.9012e-02 (6.7182e-02)	Acc@1  97.27 ( 97.72)	Acc@5 100.00 (100.00)
Epoch: [63][24/25]	Time  0.671 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.7483e-02 (6.3146e-02)	Acc@1  98.05 ( 97.97)	Acc@5 100.00 (100.00)
Test Epoch: [63/200], lr: 0.000050, acc: 95.8750, best: 96.0000
Epoch: [64][ 0/25]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 9.8612e-02 (9.8612e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [64][12/25]	Time  0.689 ( 0.678)	Data  0.007 ( 0.006)	Loss 5.4622e-02 (6.2070e-02)	Acc@1  98.44 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [64][24/25]	Time  0.667 ( 0.679)	Data  0.006 ( 0.006)	Loss 7.3512e-02 (6.3569e-02)	Acc@1  98.05 ( 98.03)	Acc@5 100.00 (100.00)
Test Epoch: [64/200], lr: 0.000050, acc: 95.6875, best: 96.0000
Epoch: [65][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 5.8184e-02 (5.8184e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [65][12/25]	Time  0.669 ( 0.674)	Data  0.006 ( 0.007)	Loss 4.3797e-02 (6.3067e-02)	Acc@1  99.22 ( 98.02)	Acc@5 100.00 (100.00)
Epoch: [65][24/25]	Time  0.671 ( 0.676)	Data  0.007 ( 0.006)	Loss 4.6187e-02 (6.2812e-02)	Acc@1  99.22 ( 97.98)	Acc@5 100.00 (100.00)
Test Epoch: [65/200], lr: 0.000050, acc: 95.6875, best: 96.0000
Epoch: [66][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 3.7939e-02 (3.7939e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [66][12/25]	Time  0.674 ( 0.672)	Data  0.006 ( 0.006)	Loss 6.3354e-02 (6.8140e-02)	Acc@1  98.05 ( 97.93)	Acc@5 100.00 (100.00)
Epoch: [66][24/25]	Time  0.664 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.8130e-02 (6.3217e-02)	Acc@1  98.05 ( 98.08)	Acc@5 100.00 (100.00)
Test Epoch: [66/200], lr: 0.000050, acc: 95.8750, best: 96.0000
Epoch: [67][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 5.2693e-02 (5.2693e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [67][12/25]	Time  0.666 ( 0.677)	Data  0.007 ( 0.007)	Loss 3.6290e-02 (5.9031e-02)	Acc@1  99.61 ( 98.17)	Acc@5 100.00 (100.00)
Epoch: [67][24/25]	Time  0.668 ( 0.679)	Data  0.006 ( 0.006)	Loss 4.5025e-02 (6.1621e-02)	Acc@1  99.22 ( 98.16)	Acc@5 100.00 (100.00)
Test Epoch: [67/200], lr: 0.000050, acc: 96.0000, best: 96.0000
Epoch: [68][ 0/25]	Time  0.665 ( 0.665)	Data  0.007 ( 0.007)	Loss 5.0533e-02 (5.0533e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [68][12/25]	Time  0.669 ( 0.670)	Data  0.006 ( 0.006)	Loss 5.4858e-02 (5.8222e-02)	Acc@1  98.05 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [68][24/25]	Time  0.670 ( 0.681)	Data  0.006 ( 0.006)	Loss 5.9915e-02 (6.0000e-02)	Acc@1  98.05 ( 98.23)	Acc@5 100.00 (100.00)
Test Epoch: [68/200], lr: 0.000050, acc: 95.9375, best: 96.0000
Epoch: [69][ 0/25]	Time  0.671 ( 0.671)	Data  0.007 ( 0.007)	Loss 4.7478e-02 (4.7478e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [69][12/25]	Time  0.668 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.7320e-02 (5.7979e-02)	Acc@1  98.05 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [69][24/25]	Time  0.667 ( 0.673)	Data  0.006 ( 0.006)	Loss 7.7756e-02 (5.9651e-02)	Acc@1  96.88 ( 98.11)	Acc@5 100.00 (100.00)
Test Epoch: [69/200], lr: 0.000050, acc: 95.7500, best: 96.0000
Epoch: [70][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 6.3598e-02 (6.3598e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [70][12/25]	Time  0.670 ( 0.683)	Data  0.006 ( 0.006)	Loss 3.3813e-02 (5.4527e-02)	Acc@1  99.61 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [70][24/25]	Time  0.670 ( 0.679)	Data  0.006 ( 0.006)	Loss 8.3192e-02 (5.9073e-02)	Acc@1  97.27 ( 98.08)	Acc@5 100.00 (100.00)
Test Epoch: [70/200], lr: 0.000050, acc: 96.0625, best: 96.0625
Epoch: [71][ 0/25]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 4.6012e-02 (4.6012e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [71][12/25]	Time  0.665 ( 0.668)	Data  0.006 ( 0.006)	Loss 5.7217e-02 (5.5570e-02)	Acc@1  99.22 ( 98.11)	Acc@5 100.00 (100.00)
Epoch: [71][24/25]	Time  0.668 ( 0.677)	Data  0.006 ( 0.006)	Loss 4.7332e-02 (5.8383e-02)	Acc@1  99.22 ( 98.12)	Acc@5 100.00 (100.00)
Test Epoch: [71/200], lr: 0.000050, acc: 96.3125, best: 96.3125
Epoch: [72][ 0/25]	Time  0.682 ( 0.682)	Data  0.008 ( 0.008)	Loss 5.2738e-02 (5.2738e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [72][12/25]	Time  0.682 ( 0.670)	Data  0.006 ( 0.007)	Loss 1.0279e-01 (5.9406e-02)	Acc@1  96.09 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [72][24/25]	Time  0.753 ( 0.677)	Data  0.007 ( 0.006)	Loss 6.2951e-02 (5.9145e-02)	Acc@1  97.66 ( 98.16)	Acc@5 100.00 (100.00)
Test Epoch: [72/200], lr: 0.000050, acc: 95.0625, best: 96.3125
Epoch: [73][ 0/25]	Time  0.659 ( 0.659)	Data  0.007 ( 0.007)	Loss 4.8547e-02 (4.8547e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [73][12/25]	Time  0.752 ( 0.676)	Data  0.007 ( 0.006)	Loss 3.1351e-02 (5.2541e-02)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [73][24/25]	Time  0.672 ( 0.673)	Data  0.006 ( 0.006)	Loss 7.4898e-02 (5.6961e-02)	Acc@1  96.88 ( 98.20)	Acc@5 100.00 (100.00)
Test Epoch: [73/200], lr: 0.000050, acc: 95.5000, best: 96.3125
Epoch: [74][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 5.7745e-02 (5.7745e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [74][12/25]	Time  0.664 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.6379e-02 (5.8599e-02)	Acc@1  98.05 ( 97.99)	Acc@5 100.00 (100.00)
Epoch: [74][24/25]	Time  0.664 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.5029e-02 (6.0014e-02)	Acc@1  98.44 ( 97.98)	Acc@5 100.00 ( 99.98)
Test Epoch: [74/200], lr: 0.000050, acc: 95.6875, best: 96.3125
Epoch: [75][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 5.6469e-02 (5.6469e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [75][12/25]	Time  0.673 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.9703e-02 (5.4675e-02)	Acc@1  98.05 ( 98.50)	Acc@5 100.00 (100.00)
Epoch: [75][24/25]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 3.8698e-02 (5.8814e-02)	Acc@1  98.83 ( 98.27)	Acc@5 100.00 (100.00)
Test Epoch: [75/200], lr: 0.000050, acc: 95.4375, best: 96.3125
Epoch: [76][ 0/25]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 7.0781e-02 (7.0781e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [76][12/25]	Time  0.660 ( 0.669)	Data  0.006 ( 0.006)	Loss 5.2937e-02 (5.8607e-02)	Acc@1  98.05 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [76][24/25]	Time  0.662 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.7203e-02 (6.0468e-02)	Acc@1  98.05 ( 98.16)	Acc@5 100.00 (100.00)
Test Epoch: [76/200], lr: 0.000050, acc: 95.5000, best: 96.3125
Epoch: [77][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 5.9024e-02 (5.9024e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [77][12/25]	Time  0.680 ( 0.679)	Data  0.006 ( 0.006)	Loss 7.0227e-02 (5.5802e-02)	Acc@1  97.66 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [77][24/25]	Time  0.667 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.6882e-02 (5.8708e-02)	Acc@1  97.66 ( 98.20)	Acc@5 100.00 (100.00)
Test Epoch: [77/200], lr: 0.000050, acc: 95.0000, best: 96.3125
Epoch: [78][ 0/25]	Time  0.658 ( 0.658)	Data  0.007 ( 0.007)	Loss 4.6816e-02 (4.6816e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [78][12/25]	Time  0.815 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.1706e-02 (6.1837e-02)	Acc@1  98.44 ( 97.96)	Acc@5 100.00 (100.00)
Epoch: [78][24/25]	Time  0.673 ( 0.677)	Data  0.006 ( 0.006)	Loss 8.3412e-02 (6.0430e-02)	Acc@1  96.48 ( 97.97)	Acc@5 100.00 (100.00)
Test Epoch: [78/200], lr: 0.000050, acc: 95.1875, best: 96.3125
Epoch: [79][ 0/25]	Time  0.659 ( 0.659)	Data  0.007 ( 0.007)	Loss 6.8087e-02 (6.8087e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [79][12/25]	Time  0.682 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.3168e-02 (6.2233e-02)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 (100.00)
Epoch: [79][24/25]	Time  0.763 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.9599e-02 (5.8900e-02)	Acc@1  98.05 ( 98.22)	Acc@5 100.00 (100.00)
Test Epoch: [79/200], lr: 0.000050, acc: 95.7500, best: 96.3125
Epoch: [80][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 5.2500e-02 (5.2500e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [80][12/25]	Time  0.668 ( 0.675)	Data  0.006 ( 0.006)	Loss 5.1226e-02 (5.3397e-02)	Acc@1  98.44 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [80][24/25]	Time  0.668 ( 0.671)	Data  0.006 ( 0.006)	Loss 5.0836e-02 (5.5809e-02)	Acc@1  98.05 ( 98.19)	Acc@5 100.00 (100.00)
Test Epoch: [80/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [81][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 6.6091e-02 (6.6091e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [81][12/25]	Time  0.670 ( 0.681)	Data  0.007 ( 0.006)	Loss 5.1619e-02 (5.2700e-02)	Acc@1  99.22 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [81][24/25]	Time  0.676 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.3033e-02 (5.5614e-02)	Acc@1  97.66 ( 98.33)	Acc@5 100.00 (100.00)
Test Epoch: [81/200], lr: 0.000005, acc: 95.7500, best: 96.3125
Epoch: [82][ 0/25]	Time  0.665 ( 0.665)	Data  0.007 ( 0.007)	Loss 3.9875e-02 (3.9875e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [82][12/25]	Time  0.665 ( 0.666)	Data  0.006 ( 0.006)	Loss 5.7898e-02 (5.0586e-02)	Acc@1  98.05 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [82][24/25]	Time  0.674 ( 0.675)	Data  0.006 ( 0.006)	Loss 7.0657e-02 (5.4933e-02)	Acc@1  97.66 ( 98.38)	Acc@5 100.00 (100.00)
Test Epoch: [82/200], lr: 0.000005, acc: 96.0000, best: 96.3125
Epoch: [83][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 4.1971e-02 (4.1971e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [83][12/25]	Time  0.684 ( 0.675)	Data  0.006 ( 0.006)	Loss 7.1887e-02 (6.0312e-02)	Acc@1  96.48 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [83][24/25]	Time  0.670 ( 0.672)	Data  0.007 ( 0.006)	Loss 3.6007e-02 (5.4423e-02)	Acc@1  98.83 ( 98.34)	Acc@5 100.00 (100.00)
Test Epoch: [83/200], lr: 0.000005, acc: 96.0625, best: 96.3125
Epoch: [84][ 0/25]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 5.0823e-02 (5.0823e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [84][12/25]	Time  0.677 ( 0.688)	Data  0.007 ( 0.006)	Loss 2.1526e-02 (5.7246e-02)	Acc@1  99.61 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [84][24/25]	Time  0.672 ( 0.680)	Data  0.006 ( 0.006)	Loss 3.1860e-02 (5.5945e-02)	Acc@1  99.61 ( 98.27)	Acc@5 100.00 (100.00)
Test Epoch: [84/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [85][ 0/25]	Time  0.660 ( 0.660)	Data  0.007 ( 0.007)	Loss 4.4108e-02 (4.4108e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [85][12/25]	Time  0.669 ( 0.686)	Data  0.006 ( 0.014)	Loss 4.8084e-02 (5.7280e-02)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 (100.00)
Epoch: [85][24/25]	Time  0.660 ( 0.678)	Data  0.006 ( 0.010)	Loss 3.8939e-02 (5.5307e-02)	Acc@1  99.22 ( 98.22)	Acc@5 100.00 (100.00)
Test Epoch: [85/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [86][ 0/25]	Time  0.662 ( 0.662)	Data  0.007 ( 0.007)	Loss 4.0064e-02 (4.0064e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [86][12/25]	Time  0.662 ( 0.665)	Data  0.006 ( 0.006)	Loss 4.1804e-02 (5.4299e-02)	Acc@1  98.83 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [86][24/25]	Time  0.664 ( 0.672)	Data  0.007 ( 0.006)	Loss 5.7373e-02 (5.6340e-02)	Acc@1  98.05 ( 98.22)	Acc@5 100.00 (100.00)
Test Epoch: [86/200], lr: 0.000005, acc: 95.5625, best: 96.3125
Epoch: [87][ 0/25]	Time  0.659 ( 0.659)	Data  0.007 ( 0.007)	Loss 6.1323e-02 (6.1323e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [87][12/25]	Time  0.665 ( 0.665)	Data  0.006 ( 0.006)	Loss 4.4203e-02 (5.3269e-02)	Acc@1  98.83 ( 98.50)	Acc@5 100.00 (100.00)
Epoch: [87][24/25]	Time  0.680 ( 0.671)	Data  0.006 ( 0.006)	Loss 6.1003e-02 (5.6061e-02)	Acc@1  97.27 ( 98.25)	Acc@5 100.00 (100.00)
Test Epoch: [87/200], lr: 0.000005, acc: 95.7500, best: 96.3125
Epoch: [88][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 5.9686e-02 (5.9686e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [88][12/25]	Time  0.677 ( 0.680)	Data  0.006 ( 0.006)	Loss 7.0552e-02 (5.9127e-02)	Acc@1  96.48 ( 97.93)	Acc@5 100.00 (100.00)
Epoch: [88][24/25]	Time  0.674 ( 0.675)	Data  0.006 ( 0.006)	Loss 6.4061e-02 (5.6385e-02)	Acc@1  97.66 ( 98.17)	Acc@5 100.00 (100.00)
Test Epoch: [88/200], lr: 0.000005, acc: 95.3750, best: 96.3125
Epoch: [89][ 0/25]	Time  0.661 ( 0.661)	Data  0.006 ( 0.006)	Loss 3.3059e-02 (3.3059e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [89][12/25]	Time  0.663 ( 0.675)	Data  0.006 ( 0.007)	Loss 6.3476e-02 (5.3720e-02)	Acc@1  98.05 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [89][24/25]	Time  0.673 ( 0.675)	Data  0.007 ( 0.007)	Loss 7.2073e-02 (5.5610e-02)	Acc@1  97.27 ( 98.11)	Acc@5 100.00 (100.00)
Test Epoch: [89/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [90][ 0/25]	Time  0.658 ( 0.658)	Data  0.006 ( 0.006)	Loss 6.3714e-02 (6.3714e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [90][12/25]	Time  0.683 ( 0.675)	Data  0.006 ( 0.006)	Loss 5.3971e-02 (5.6797e-02)	Acc@1  98.05 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [90][24/25]	Time  0.673 ( 0.671)	Data  0.006 ( 0.006)	Loss 5.7293e-02 (5.4865e-02)	Acc@1  98.44 ( 98.28)	Acc@5 100.00 (100.00)
Test Epoch: [90/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [91][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 4.9149e-02 (4.9149e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [91][12/25]	Time  0.678 ( 0.681)	Data  0.006 ( 0.006)	Loss 6.9968e-02 (5.6444e-02)	Acc@1  98.05 ( 98.11)	Acc@5 100.00 (100.00)
Epoch: [91][24/25]	Time  0.662 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.6699e-02 (5.6073e-02)	Acc@1  98.44 ( 98.20)	Acc@5 100.00 (100.00)
Test Epoch: [91/200], lr: 0.000005, acc: 95.5625, best: 96.3125
Epoch: [92][ 0/25]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 5.2552e-02 (5.2552e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [92][12/25]	Time  0.670 ( 0.671)	Data  0.007 ( 0.006)	Loss 5.3080e-02 (5.5060e-02)	Acc@1  98.44 ( 98.17)	Acc@5 100.00 (100.00)
Epoch: [92][24/25]	Time  0.671 ( 0.677)	Data  0.006 ( 0.006)	Loss 6.0911e-02 (5.5529e-02)	Acc@1  98.44 ( 98.19)	Acc@5 100.00 (100.00)
Test Epoch: [92/200], lr: 0.000005, acc: 95.3750, best: 96.3125
Epoch: [93][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 5.4105e-02 (5.4105e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [93][12/25]	Time  0.664 ( 0.682)	Data  0.006 ( 0.006)	Loss 7.1274e-02 (5.7055e-02)	Acc@1  98.44 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [93][24/25]	Time  0.675 ( 0.682)	Data  0.007 ( 0.006)	Loss 3.0591e-02 (5.5057e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [93/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [94][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 5.5683e-02 (5.5683e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [94][12/25]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 8.4867e-02 (5.3183e-02)	Acc@1  96.88 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [94][24/25]	Time  0.659 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.2402e-02 (5.5958e-02)	Acc@1  98.83 ( 98.34)	Acc@5 100.00 (100.00)
Test Epoch: [94/200], lr: 0.000005, acc: 95.2500, best: 96.3125
Epoch: [95][ 0/25]	Time  0.662 ( 0.662)	Data  0.006 ( 0.006)	Loss 4.5608e-02 (4.5608e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [95][12/25]	Time  0.665 ( 0.681)	Data  0.006 ( 0.006)	Loss 8.4939e-02 (5.6772e-02)	Acc@1  97.66 ( 98.47)	Acc@5 100.00 (100.00)
Epoch: [95][24/25]	Time  0.682 ( 0.676)	Data  0.006 ( 0.006)	Loss 6.9632e-02 (5.4840e-02)	Acc@1  97.27 ( 98.45)	Acc@5 100.00 (100.00)
Test Epoch: [95/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [96][ 0/25]	Time  0.661 ( 0.661)	Data  0.007 ( 0.007)	Loss 4.8890e-02 (4.8890e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [96][12/25]	Time  0.667 ( 0.670)	Data  0.006 ( 0.006)	Loss 3.6514e-02 (5.3226e-02)	Acc@1  99.61 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [96][24/25]	Time  0.773 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.8878e-02 (5.4015e-02)	Acc@1  98.44 ( 98.22)	Acc@5 100.00 (100.00)
Test Epoch: [96/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [97][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 5.4811e-02 (5.4811e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [97][12/25]	Time  0.682 ( 0.669)	Data  0.006 ( 0.006)	Loss 7.4991e-02 (5.9483e-02)	Acc@1  97.27 ( 97.96)	Acc@5 100.00 (100.00)
Epoch: [97][24/25]	Time  0.667 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.0311e-02 (5.4612e-02)	Acc@1  99.61 ( 98.19)	Acc@5 100.00 (100.00)
Test Epoch: [97/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [98][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 7.3203e-02 (7.3203e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [98][12/25]	Time  0.671 ( 0.682)	Data  0.006 ( 0.006)	Loss 2.9016e-02 (5.8907e-02)	Acc@1 100.00 ( 97.87)	Acc@5 100.00 (100.00)
Epoch: [98][24/25]	Time  0.667 ( 0.677)	Data  0.007 ( 0.006)	Loss 6.1504e-02 (5.3331e-02)	Acc@1  98.44 ( 98.23)	Acc@5 100.00 (100.00)
Test Epoch: [98/200], lr: 0.000005, acc: 94.8125, best: 96.3125
Epoch: [99][ 0/25]	Time  0.686 ( 0.686)	Data  0.007 ( 0.007)	Loss 5.0080e-02 (5.0080e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [99][12/25]	Time  0.672 ( 0.679)	Data  0.006 ( 0.006)	Loss 4.3914e-02 (5.2870e-02)	Acc@1  99.22 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [99][24/25]	Time  0.687 ( 0.677)	Data  0.008 ( 0.006)	Loss 3.8072e-02 (5.3087e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [99/200], lr: 0.000005, acc: 94.8125, best: 96.3125
Epoch: [100][ 0/25]	Time  0.667 ( 0.667)	Data  0.007 ( 0.007)	Loss 3.0146e-02 (3.0146e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [100][12/25]	Time  0.664 ( 0.678)	Data  0.006 ( 0.006)	Loss 6.7271e-02 (5.1958e-02)	Acc@1  97.66 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [100][24/25]	Time  0.672 ( 0.673)	Data  0.006 ( 0.006)	Loss 6.3640e-02 (5.2913e-02)	Acc@1  98.05 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [100/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [101][ 0/25]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 2.8298e-02 (2.8298e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [101][12/25]	Time  0.667 ( 0.675)	Data  0.006 ( 0.006)	Loss 3.6251e-02 (5.3031e-02)	Acc@1  99.22 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [101][24/25]	Time  0.680 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.9050e-02 (5.4861e-02)	Acc@1  98.05 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [101/200], lr: 0.000005, acc: 95.3125, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [102][ 0/25]	Time  0.690 ( 0.690)	Data  0.006 ( 0.006)	Loss 4.2701e-02 (4.2701e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [102][12/25]	Time  0.663 ( 0.667)	Data  0.007 ( 0.006)	Loss 4.9142e-02 (5.7307e-02)	Acc@1  98.83 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [102][24/25]	Time  0.671 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.7232e-02 (5.4173e-02)	Acc@1  98.05 ( 98.41)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [102/200], lr: 0.000005, acc: 95.0625, best: 96.3125
Epoch: [103][ 0/25]	Time  0.661 ( 0.661)	Data  0.007 ( 0.007)	Loss 3.6668e-02 (3.6668e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [103][12/25]	Time  0.664 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.1439e-02 (4.9825e-02)	Acc@1  99.22 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [103][24/25]	Time  0.762 ( 0.674)	Data  0.102 ( 0.010)	Loss 9.0678e-02 (5.4406e-02)	Acc@1  96.09 ( 98.34)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [103/200], lr: 0.000005, acc: 95.2500, best: 96.3125
Epoch: [104][ 0/25]	Time  0.681 ( 0.681)	Data  0.006 ( 0.006)	Loss 5.5679e-02 (5.5679e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [104][12/25]	Time  0.680 ( 0.687)	Data  0.007 ( 0.006)	Loss 6.6021e-02 (5.5288e-02)	Acc@1  98.05 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [104][24/25]	Time  0.670 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.5589e-02 (5.3588e-02)	Acc@1  97.66 ( 98.44)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [104/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [105][ 0/25]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 8.0173e-02 (8.0173e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [105][12/25]	Time  0.670 ( 0.679)	Data  0.007 ( 0.014)	Loss 4.5235e-02 (5.8149e-02)	Acc@1  98.83 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [105][24/25]	Time  0.661 ( 0.679)	Data  0.006 ( 0.010)	Loss 6.5323e-02 (5.3966e-02)	Acc@1  96.48 ( 98.36)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [105/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [106][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 4.9197e-02 (4.9197e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [106][12/25]	Time  0.693 ( 0.668)	Data  0.006 ( 0.006)	Loss 5.2535e-02 (5.1688e-02)	Acc@1  98.44 ( 98.50)	Acc@5 100.00 (100.00)
Epoch: [106][24/25]	Time  0.667 ( 0.675)	Data  0.006 ( 0.006)	Loss 5.1490e-02 (5.4767e-02)	Acc@1  98.44 ( 98.38)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [106/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [107][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 6.4204e-02 (6.4204e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [107][12/25]	Time  0.666 ( 0.668)	Data  0.008 ( 0.006)	Loss 4.6119e-02 (5.6970e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [107][24/25]	Time  0.659 ( 0.670)	Data  0.006 ( 0.006)	Loss 6.6642e-02 (5.3509e-02)	Acc@1  98.44 ( 98.42)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [107/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [108][ 0/25]	Time  0.686 ( 0.686)	Data  0.007 ( 0.007)	Loss 4.0218e-02 (4.0218e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [108][12/25]	Time  0.662 ( 0.688)	Data  0.006 ( 0.006)	Loss 7.1676e-02 (4.8194e-02)	Acc@1  96.88 ( 98.65)	Acc@5 100.00 (100.00)
Epoch: [108][24/25]	Time  0.667 ( 0.677)	Data  0.006 ( 0.006)	Loss 3.8217e-02 (5.3574e-02)	Acc@1  99.61 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [108/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [109][ 0/25]	Time  0.659 ( 0.659)	Data  0.007 ( 0.007)	Loss 5.9080e-02 (5.9080e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [109][12/25]	Time  0.658 ( 0.673)	Data  0.006 ( 0.006)	Loss 6.5159e-02 (5.6107e-02)	Acc@1  98.83 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [109][24/25]	Time  0.671 ( 0.676)	Data  0.007 ( 0.010)	Loss 4.7528e-02 (5.2841e-02)	Acc@1  98.44 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [109/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [110][ 0/25]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 7.5621e-02 (7.5621e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [110][12/25]	Time  0.677 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.2486e-02 (4.9788e-02)	Acc@1  98.83 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [110][24/25]	Time  0.671 ( 0.680)	Data  0.006 ( 0.006)	Loss 6.7774e-02 (5.4313e-02)	Acc@1  97.27 ( 98.30)	Acc@5 100.00 (100.00)
Test Epoch: [110/200], lr: 0.000005, acc: 95.0625, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [111][ 0/25]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 5.2362e-02 (5.2362e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [111][12/25]	Time  0.678 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.3723e-02 (5.3541e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [111][24/25]	Time  0.666 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.2132e-02 (5.4900e-02)	Acc@1  99.22 ( 98.38)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [111/200], lr: 0.000005, acc: 95.5625, best: 96.3125
Epoch: [112][ 0/25]	Time  0.667 ( 0.667)	Data  0.007 ( 0.007)	Loss 5.4345e-02 (5.4345e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [112][12/25]	Time  0.772 ( 0.677)	Data  0.007 ( 0.007)	Loss 4.2262e-02 (5.6530e-02)	Acc@1  98.83 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [112][24/25]	Time  0.670 ( 0.676)	Data  0.007 ( 0.006)	Loss 4.0824e-02 (5.5185e-02)	Acc@1  99.61 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [112/200], lr: 0.000005, acc: 95.0625, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [113][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 5.4408e-02 (5.4408e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [113][12/25]	Time  0.667 ( 0.679)	Data  0.007 ( 0.006)	Loss 5.2063e-02 (5.0757e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [113][24/25]	Time  0.671 ( 0.678)	Data  0.007 ( 0.006)	Loss 6.1298e-02 (5.3676e-02)	Acc@1  98.05 ( 98.38)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [113/200], lr: 0.000005, acc: 95.2500, best: 96.3125
Epoch: [114][ 0/25]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 7.0405e-02 (7.0405e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [114][12/25]	Time  0.674 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.0634e-02 (5.6480e-02)	Acc@1  97.66 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [114][24/25]	Time  0.675 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.3464e-02 (5.6138e-02)	Acc@1  98.44 ( 98.33)	Acc@5 100.00 (100.00)
Test Epoch: [114/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [115][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 4.8767e-02 (4.8767e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [115][12/25]	Time  0.667 ( 0.674)	Data  0.006 ( 0.006)	Loss 6.4785e-02 (5.7045e-02)	Acc@1  98.83 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [115][24/25]	Time  0.670 ( 0.676)	Data  0.007 ( 0.006)	Loss 5.3173e-02 (5.5520e-02)	Acc@1  98.05 ( 98.28)	Acc@5 100.00 (100.00)
Test Epoch: [115/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [116][ 0/25]	Time  0.664 ( 0.664)	Data  0.007 ( 0.007)	Loss 4.8216e-02 (4.8216e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [116][12/25]	Time  0.667 ( 0.672)	Data  0.006 ( 0.006)	Loss 4.9493e-02 (5.3824e-02)	Acc@1  98.05 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [116][24/25]	Time  0.664 ( 0.676)	Data  0.006 ( 0.006)	Loss 3.1574e-02 (5.4692e-02)	Acc@1  99.61 ( 98.27)	Acc@5 100.00 (100.00)
Test Epoch: [116/200], lr: 0.000005, acc: 94.8125, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [117][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 6.1657e-02 (6.1657e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [117][12/25]	Time  0.754 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.5489e-02 (5.5226e-02)	Acc@1  98.83 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [117][24/25]	Time  0.661 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.2476e-02 (5.6064e-02)	Acc@1  99.22 ( 98.31)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [117/200], lr: 0.000005, acc: 94.9375, best: 96.3125
Epoch: [118][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 4.2313e-02 (4.2313e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [118][12/25]	Time  0.667 ( 0.685)	Data  0.006 ( 0.014)	Loss 3.4945e-02 (4.8862e-02)	Acc@1  99.61 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [118][24/25]	Time  0.668 ( 0.680)	Data  0.006 ( 0.010)	Loss 6.4895e-02 (5.5560e-02)	Acc@1  97.27 ( 98.28)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [118/200], lr: 0.000005, acc: 94.8750, best: 96.3125
Epoch: [119][ 0/25]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 6.4092e-02 (6.4092e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [119][12/25]	Time  0.671 ( 0.679)	Data  0.007 ( 0.006)	Loss 6.1722e-02 (5.9255e-02)	Acc@1  96.88 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [119][24/25]	Time  0.668 ( 0.679)	Data  0.006 ( 0.010)	Loss 5.0686e-02 (5.6717e-02)	Acc@1  98.83 ( 98.30)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [119/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [120][ 0/25]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 3.4922e-02 (3.4922e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [120][12/25]	Time  0.671 ( 0.674)	Data  0.006 ( 0.006)	Loss 8.4630e-02 (5.2817e-02)	Acc@1  96.88 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [120][24/25]	Time  0.680 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.9367e-02 (5.5404e-02)	Acc@1  98.83 ( 98.25)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [120/200], lr: 0.000005, acc: 94.9375, best: 96.3125
Epoch: [121][ 0/25]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 8.2134e-02 (8.2134e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [121][12/25]	Time  0.668 ( 0.679)	Data  0.007 ( 0.006)	Loss 6.4930e-02 (5.7830e-02)	Acc@1  98.44 ( 98.11)	Acc@5 100.00 (100.00)
Epoch: [121][24/25]	Time  0.668 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.1593e-02 (5.4899e-02)	Acc@1  99.61 ( 98.31)	Acc@5 100.00 (100.00)
Test Epoch: [121/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [122][ 0/25]	Time  0.695 ( 0.695)	Data  0.007 ( 0.007)	Loss 3.6787e-02 (3.6787e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [122][12/25]	Time  0.698 ( 0.691)	Data  0.009 ( 0.007)	Loss 4.8937e-02 (5.2969e-02)	Acc@1  98.05 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [122][24/25]	Time  0.673 ( 0.683)	Data  0.006 ( 0.007)	Loss 7.1754e-02 (5.5426e-02)	Acc@1  98.05 ( 98.19)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [122/200], lr: 0.000005, acc: 95.2500, best: 96.3125
Epoch: [123][ 0/25]	Time  0.664 ( 0.664)	Data  0.007 ( 0.007)	Loss 4.9387e-02 (4.9387e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [123][12/25]	Time  0.670 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.0687e-02 (5.4283e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [123][24/25]	Time  0.762 ( 0.679)	Data  0.106 ( 0.010)	Loss 5.4585e-02 (5.5686e-02)	Acc@1  98.44 ( 98.19)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [123/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [124][ 0/25]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 5.0313e-02 (5.0313e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [124][12/25]	Time  0.669 ( 0.679)	Data  0.006 ( 0.006)	Loss 5.5959e-02 (5.2181e-02)	Acc@1  98.05 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [124][24/25]	Time  0.674 ( 0.676)	Data  0.006 ( 0.006)	Loss 7.2238e-02 (5.4973e-02)	Acc@1  97.66 ( 98.19)	Acc@5 100.00 (100.00)
Test Epoch: [124/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [125][ 0/25]	Time  0.669 ( 0.669)	Data  0.006 ( 0.006)	Loss 5.6443e-02 (5.6443e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [125][12/25]	Time  0.669 ( 0.677)	Data  0.007 ( 0.014)	Loss 2.6262e-02 (5.5478e-02)	Acc@1  99.61 ( 98.17)	Acc@5 100.00 (100.00)
Epoch: [125][24/25]	Time  0.672 ( 0.677)	Data  0.006 ( 0.010)	Loss 6.8571e-02 (5.4739e-02)	Acc@1  98.05 ( 98.33)	Acc@5 100.00 (100.00)
Test Epoch: [125/200], lr: 0.000005, acc: 95.1250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [126][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 7.1634e-02 (7.1634e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [126][12/25]	Time  0.665 ( 0.671)	Data  0.006 ( 0.006)	Loss 4.1140e-02 (5.2670e-02)	Acc@1  98.83 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [126][24/25]	Time  0.677 ( 0.679)	Data  0.006 ( 0.006)	Loss 5.2599e-02 (5.5198e-02)	Acc@1  98.83 ( 98.30)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [126/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [127][ 0/25]	Time  0.692 ( 0.692)	Data  0.007 ( 0.007)	Loss 3.9678e-02 (3.9678e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [127][12/25]	Time  0.672 ( 0.682)	Data  0.006 ( 0.006)	Loss 5.6031e-02 (4.9888e-02)	Acc@1  98.05 ( 98.56)	Acc@5 100.00 (100.00)
Epoch: [127][24/25]	Time  0.672 ( 0.678)	Data  0.007 ( 0.006)	Loss 2.9178e-02 (5.6410e-02)	Acc@1  99.22 ( 98.30)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [127/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [128][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 3.9626e-02 (3.9626e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [128][12/25]	Time  0.675 ( 0.688)	Data  0.006 ( 0.006)	Loss 5.0706e-02 (5.0908e-02)	Acc@1  98.83 ( 98.56)	Acc@5 100.00 (100.00)
Epoch: [128][24/25]	Time  0.677 ( 0.681)	Data  0.006 ( 0.006)	Loss 5.8565e-02 (5.4886e-02)	Acc@1  98.05 ( 98.31)	Acc@5 100.00 (100.00)
Test Epoch: [128/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [129][ 0/25]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 5.3080e-02 (5.3080e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [129][12/25]	Time  0.669 ( 0.672)	Data  0.007 ( 0.006)	Loss 5.1688e-02 (5.5066e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [129][24/25]	Time  0.678 ( 0.681)	Data  0.008 ( 0.010)	Loss 3.8131e-02 (5.6243e-02)	Acc@1  98.83 ( 98.30)	Acc@5 100.00 (100.00)
Test Epoch: [129/200], lr: 0.000005, acc: 95.5000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [130][ 0/25]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 6.8561e-02 (6.8561e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [130][12/25]	Time  0.667 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.9240e-02 (5.6967e-02)	Acc@1  98.83 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [130][24/25]	Time  0.675 ( 0.675)	Data  0.007 ( 0.006)	Loss 3.4897e-02 (5.5587e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [130/200], lr: 0.000005, acc: 95.1250, best: 96.3125
Epoch: [131][ 0/25]	Time  0.684 ( 0.684)	Data  0.006 ( 0.006)	Loss 7.8722e-02 (7.8722e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [131][12/25]	Time  0.676 ( 0.681)	Data  0.006 ( 0.006)	Loss 6.2362e-02 (5.5974e-02)	Acc@1  97.66 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [131][24/25]	Time  0.673 ( 0.682)	Data  0.006 ( 0.006)	Loss 6.5342e-02 (5.5671e-02)	Acc@1  97.66 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [131/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [132][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 4.0744e-02 (4.0744e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [132][12/25]	Time  0.670 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.5934e-02 (5.2913e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [132][24/25]	Time  0.669 ( 0.678)	Data  0.006 ( 0.006)	Loss 9.2980e-02 (5.5148e-02)	Acc@1  97.27 ( 98.45)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [132/200], lr: 0.000005, acc: 95.1875, best: 96.3125
Epoch: [133][ 0/25]	Time  0.683 ( 0.683)	Data  0.007 ( 0.007)	Loss 4.6834e-02 (4.6834e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [133][12/25]	Time  0.669 ( 0.683)	Data  0.007 ( 0.006)	Loss 4.8516e-02 (5.7173e-02)	Acc@1  98.05 ( 98.14)	Acc@5 100.00 (100.00)
Epoch: [133][24/25]	Time  0.665 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.3791e-02 (5.5586e-02)	Acc@1  98.83 ( 98.31)	Acc@5 100.00 (100.00)
Test Epoch: [133/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [134][ 0/25]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.9322e-02 (4.9322e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [134][12/25]	Time  0.669 ( 0.677)	Data  0.007 ( 0.006)	Loss 3.5692e-02 (5.3679e-02)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [134][24/25]	Time  0.666 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.6615e-02 (5.4744e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [134/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [135][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 8.1458e-02 (8.1458e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [135][12/25]	Time  0.663 ( 0.664)	Data  0.006 ( 0.006)	Loss 3.7686e-02 (5.4788e-02)	Acc@1  99.22 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [135][24/25]	Time  0.665 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.9679e-02 (5.4379e-02)	Acc@1  97.27 ( 98.42)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [135/200], lr: 0.000005, acc: 95.0000, best: 96.3125
Epoch: [136][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 7.6078e-02 (7.6078e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [136][12/25]	Time  0.662 ( 0.668)	Data  0.007 ( 0.006)	Loss 6.3762e-02 (5.7433e-02)	Acc@1  97.66 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [136][24/25]	Time  0.679 ( 0.672)	Data  0.007 ( 0.006)	Loss 6.1347e-02 (5.3414e-02)	Acc@1  98.44 ( 98.42)	Acc@5 100.00 (100.00)
Test Epoch: [136/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [137][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 4.3900e-02 (4.3900e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [137][12/25]	Time  0.672 ( 0.682)	Data  0.006 ( 0.006)	Loss 7.3525e-02 (5.4250e-02)	Acc@1  97.66 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [137][24/25]	Time  0.673 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.9515e-02 (5.3466e-02)	Acc@1  98.83 ( 98.42)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [137/200], lr: 0.000005, acc: 95.8750, best: 96.3125
Epoch: [138][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 4.8306e-02 (4.8306e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [138][12/25]	Time  0.666 ( 0.672)	Data  0.006 ( 0.006)	Loss 6.1917e-02 (5.0775e-02)	Acc@1  98.83 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [138][24/25]	Time  0.665 ( 0.673)	Data  0.006 ( 0.006)	Loss 6.3166e-02 (5.3236e-02)	Acc@1  98.05 ( 98.61)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [138/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [139][ 0/25]	Time  0.661 ( 0.661)	Data  0.007 ( 0.007)	Loss 4.6243e-02 (4.6243e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [139][12/25]	Time  0.660 ( 0.668)	Data  0.006 ( 0.006)	Loss 3.6765e-02 (5.1709e-02)	Acc@1  99.61 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [139][24/25]	Time  0.663 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.8926e-02 (5.3344e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [139/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [140][ 0/25]	Time  0.695 ( 0.695)	Data  0.006 ( 0.006)	Loss 7.7291e-02 (7.7291e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [140][12/25]	Time  0.667 ( 0.670)	Data  0.006 ( 0.006)	Loss 4.8132e-02 (5.4588e-02)	Acc@1  98.44 ( 98.50)	Acc@5 100.00 (100.00)
Epoch: [140][24/25]	Time  0.669 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.2807e-02 (5.5108e-02)	Acc@1  98.05 ( 98.45)	Acc@5 100.00 (100.00)
Test Epoch: [140/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [141][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 5.0325e-02 (5.0325e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [141][12/25]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 4.5339e-02 (5.4441e-02)	Acc@1  98.05 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [141][24/25]	Time  0.679 ( 0.679)	Data  0.006 ( 0.006)	Loss 4.9978e-02 (5.5783e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [141/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [142][ 0/25]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 5.4276e-02 (5.4276e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [142][12/25]	Time  0.667 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.8652e-02 (5.7525e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [142][24/25]	Time  0.666 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.0728e-02 (5.5565e-02)	Acc@1  99.22 ( 98.42)	Acc@5 100.00 (100.00)
Test Epoch: [142/200], lr: 0.000005, acc: 95.5000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [143][ 0/25]	Time  0.769 ( 0.769)	Data  0.108 ( 0.108)	Loss 6.9021e-02 (6.9021e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [143][12/25]	Time  0.676 ( 0.687)	Data  0.007 ( 0.014)	Loss 5.4613e-02 (5.1338e-02)	Acc@1  97.66 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [143][24/25]	Time  0.671 ( 0.679)	Data  0.006 ( 0.010)	Loss 4.8341e-02 (5.5400e-02)	Acc@1  98.44 ( 98.33)	Acc@5 100.00 (100.00)
Test Epoch: [143/200], lr: 0.000005, acc: 95.6250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [144][ 0/25]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.3469e-02 (5.3469e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [144][12/25]	Time  0.671 ( 0.683)	Data  0.006 ( 0.006)	Loss 6.5336e-02 (5.9394e-02)	Acc@1  98.83 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [144][24/25]	Time  0.669 ( 0.681)	Data  0.007 ( 0.006)	Loss 5.3279e-02 (5.5449e-02)	Acc@1  98.83 ( 98.42)	Acc@5 100.00 (100.00)
Test Epoch: [144/200], lr: 0.000005, acc: 95.5625, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [145][ 0/25]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 7.0193e-02 (7.0193e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [145][12/25]	Time  0.676 ( 0.676)	Data  0.007 ( 0.006)	Loss 6.0255e-02 (5.9586e-02)	Acc@1  98.83 ( 98.17)	Acc@5 100.00 (100.00)
Epoch: [145][24/25]	Time  0.665 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.6274e-02 (5.4426e-02)	Acc@1  98.83 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [145/200], lr: 0.000005, acc: 95.0000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [146][ 0/25]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 5.2992e-02 (5.2992e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [146][12/25]	Time  0.754 ( 0.679)	Data  0.006 ( 0.006)	Loss 3.0582e-02 (5.3682e-02)	Acc@1  99.22 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [146][24/25]	Time  0.670 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.7346e-02 (5.5018e-02)	Acc@1  99.22 ( 98.56)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [146/200], lr: 0.000005, acc: 95.6250, best: 96.3125
Epoch: [147][ 0/25]	Time  0.676 ( 0.676)	Data  0.007 ( 0.007)	Loss 4.6708e-02 (4.6708e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [147][12/25]	Time  0.670 ( 0.691)	Data  0.006 ( 0.006)	Loss 5.1943e-02 (5.1137e-02)	Acc@1  99.22 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [147][24/25]	Time  0.681 ( 0.685)	Data  0.007 ( 0.006)	Loss 6.1532e-02 (5.5111e-02)	Acc@1  98.44 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [147/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [148][ 0/25]	Time  0.677 ( 0.677)	Data  0.006 ( 0.006)	Loss 7.0435e-02 (7.0435e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [148][12/25]	Time  0.668 ( 0.682)	Data  0.006 ( 0.006)	Loss 6.2387e-02 (5.5290e-02)	Acc@1  97.66 ( 98.47)	Acc@5 100.00 (100.00)
Epoch: [148][24/25]	Time  0.666 ( 0.681)	Data  0.006 ( 0.006)	Loss 3.2206e-02 (5.4099e-02)	Acc@1  99.61 ( 98.55)	Acc@5 100.00 (100.00)
Test Epoch: [148/200], lr: 0.000005, acc: 95.3125, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [149][ 0/25]	Time  0.682 ( 0.682)	Data  0.007 ( 0.007)	Loss 5.8500e-02 (5.8500e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [149][12/25]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 6.1722e-02 (5.6327e-02)	Acc@1  98.44 ( 98.50)	Acc@5 100.00 (100.00)
Epoch: [149][24/25]	Time  0.669 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.1146e-02 (5.4013e-02)	Acc@1  98.05 ( 98.52)	Acc@5 100.00 (100.00)
Test Epoch: [149/200], lr: 0.000005, acc: 95.1250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [150][ 0/25]	Time  0.683 ( 0.683)	Data  0.006 ( 0.006)	Loss 8.7254e-02 (8.7254e-02)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
Epoch: [150][12/25]	Time  0.666 ( 0.684)	Data  0.006 ( 0.006)	Loss 5.9024e-02 (5.9475e-02)	Acc@1  98.83 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [150][24/25]	Time  0.671 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.8855e-02 (5.4452e-02)	Acc@1  98.83 ( 98.39)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [150/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [151][ 0/25]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 8.2461e-02 (8.2461e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [151][12/25]	Time  0.674 ( 0.679)	Data  0.006 ( 0.006)	Loss 6.2563e-02 (5.7301e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [151][24/25]	Time  0.665 ( 0.680)	Data  0.007 ( 0.006)	Loss 6.4095e-02 (5.5671e-02)	Acc@1  96.88 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [151/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [152][ 0/25]	Time  0.664 ( 0.664)	Data  0.006 ( 0.006)	Loss 5.9573e-02 (5.9573e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [152][12/25]	Time  0.668 ( 0.678)	Data  0.006 ( 0.006)	Loss 4.5906e-02 (5.6067e-02)	Acc@1  98.83 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [152][24/25]	Time  0.672 ( 0.675)	Data  0.006 ( 0.006)	Loss 4.5290e-02 (5.4446e-02)	Acc@1  98.83 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [152/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [153][ 0/25]	Time  0.672 ( 0.672)	Data  0.007 ( 0.007)	Loss 4.0730e-02 (4.0730e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [153][12/25]	Time  0.677 ( 0.692)	Data  0.006 ( 0.006)	Loss 4.0217e-02 (5.7421e-02)	Acc@1  98.83 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [153][24/25]	Time  0.729 ( 0.684)	Data  0.007 ( 0.006)	Loss 5.4904e-02 (5.6188e-02)	Acc@1  99.61 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [153/200], lr: 0.000005, acc: 95.5000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [154][ 0/25]	Time  0.704 ( 0.704)	Data  0.006 ( 0.006)	Loss 5.2621e-02 (5.2621e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [154][12/25]	Time  0.668 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.6563e-02 (5.0111e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [154][24/25]	Time  0.672 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.1126e-02 (5.4204e-02)	Acc@1  99.22 ( 98.45)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [154/200], lr: 0.000005, acc: 95.5625, best: 96.3125
Epoch: [155][ 0/25]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 6.1221e-02 (6.1221e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [155][12/25]	Time  0.670 ( 0.673)	Data  0.006 ( 0.006)	Loss 6.5223e-02 (5.5614e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [155][24/25]	Time  0.677 ( 0.677)	Data  0.007 ( 0.006)	Loss 4.0618e-02 (5.4671e-02)	Acc@1  98.83 ( 98.41)	Acc@5 100.00 (100.00)
Test Epoch: [155/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [156][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 4.6743e-02 (4.6743e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [156][12/25]	Time  0.668 ( 0.687)	Data  0.007 ( 0.006)	Loss 5.3147e-02 (5.1299e-02)	Acc@1  98.05 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [156][24/25]	Time  0.670 ( 0.678)	Data  0.006 ( 0.006)	Loss 3.9610e-02 (5.2999e-02)	Acc@1  98.83 ( 98.48)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [156/200], lr: 0.000005, acc: 95.3750, best: 96.3125
Epoch: [157][ 0/25]	Time  0.674 ( 0.674)	Data  0.007 ( 0.007)	Loss 7.0717e-02 (7.0717e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [157][12/25]	Time  0.670 ( 0.685)	Data  0.006 ( 0.006)	Loss 6.5863e-02 (5.0535e-02)	Acc@1  96.88 ( 98.47)	Acc@5 100.00 (100.00)
Epoch: [157][24/25]	Time  0.662 ( 0.682)	Data  0.006 ( 0.006)	Loss 4.6162e-02 (5.1753e-02)	Acc@1  99.22 ( 98.53)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [157/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [158][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 6.4950e-02 (6.4950e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [158][12/25]	Time  0.666 ( 0.669)	Data  0.006 ( 0.006)	Loss 7.6388e-02 (5.2590e-02)	Acc@1  97.27 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [158][24/25]	Time  0.669 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.4323e-02 (5.2685e-02)	Acc@1  98.44 ( 98.52)	Acc@5 100.00 (100.00)
Test Epoch: [158/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [159][ 0/25]	Time  0.672 ( 0.672)	Data  0.006 ( 0.006)	Loss 6.3698e-02 (6.3698e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [159][12/25]	Time  0.664 ( 0.679)	Data  0.006 ( 0.006)	Loss 7.5655e-02 (5.1059e-02)	Acc@1  97.66 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [159][24/25]	Time  0.667 ( 0.679)	Data  0.006 ( 0.006)	Loss 4.0972e-02 (5.1893e-02)	Acc@1  98.83 ( 98.67)	Acc@5 100.00 (100.00)
Test Epoch: [159/200], lr: 0.000005, acc: 95.8750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [160][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 3.9356e-02 (3.9356e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [160][12/25]	Time  0.672 ( 0.673)	Data  0.007 ( 0.006)	Loss 7.0732e-02 (5.0638e-02)	Acc@1  98.05 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [160][24/25]	Time  0.665 ( 0.681)	Data  0.006 ( 0.006)	Loss 4.8275e-02 (5.2845e-02)	Acc@1  99.22 ( 98.56)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [160/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [161][ 0/25]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 5.6486e-02 (5.6486e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [161][12/25]	Time  0.669 ( 0.679)	Data  0.006 ( 0.006)	Loss 4.2601e-02 (5.4457e-02)	Acc@1  99.22 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [161][24/25]	Time  0.668 ( 0.676)	Data  0.007 ( 0.006)	Loss 5.2743e-02 (5.1927e-02)	Acc@1  98.44 ( 98.62)	Acc@5 100.00 (100.00)
Test Epoch: [161/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [162][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 4.0377e-02 (4.0377e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [162][12/25]	Time  0.674 ( 0.685)	Data  0.006 ( 0.006)	Loss 3.5930e-02 (4.9992e-02)	Acc@1  98.83 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [162][24/25]	Time  0.682 ( 0.679)	Data  0.006 ( 0.006)	Loss 5.5860e-02 (5.2597e-02)	Acc@1  98.05 ( 98.56)	Acc@5 100.00 (100.00)
Test Epoch: [162/200], lr: 0.000005, acc: 95.6250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [163][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 6.4161e-02 (6.4161e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [163][12/25]	Time  0.670 ( 0.668)	Data  0.006 ( 0.006)	Loss 7.9674e-02 (5.1746e-02)	Acc@1  97.66 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [163][24/25]	Time  0.681 ( 0.677)	Data  0.006 ( 0.006)	Loss 6.2216e-02 (5.2242e-02)	Acc@1  97.66 ( 98.53)	Acc@5 100.00 (100.00)
Test Epoch: [163/200], lr: 0.000005, acc: 95.8125, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [164][ 0/25]	Time  0.673 ( 0.673)	Data  0.007 ( 0.007)	Loss 4.6556e-02 (4.6556e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [164][12/25]	Time  0.664 ( 0.670)	Data  0.006 ( 0.006)	Loss 7.1324e-02 (5.3896e-02)	Acc@1  97.66 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [164][24/25]	Time  0.680 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.5908e-02 (5.2017e-02)	Acc@1  97.66 ( 98.52)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [164/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [165][ 0/25]	Time  0.679 ( 0.679)	Data  0.007 ( 0.007)	Loss 3.3163e-02 (3.3163e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [165][12/25]	Time  0.674 ( 0.677)	Data  0.007 ( 0.006)	Loss 5.9719e-02 (5.4593e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [165][24/25]	Time  0.669 ( 0.679)	Data  0.006 ( 0.006)	Loss 5.8378e-02 (5.2908e-02)	Acc@1  98.05 ( 98.36)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [165/200], lr: 0.000005, acc: 95.1250, best: 96.3125
Epoch: [166][ 0/25]	Time  0.684 ( 0.684)	Data  0.007 ( 0.007)	Loss 3.6002e-02 (3.6002e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [166][12/25]	Time  0.668 ( 0.682)	Data  0.006 ( 0.006)	Loss 6.4387e-02 (5.3737e-02)	Acc@1  97.27 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [166][24/25]	Time  0.675 ( 0.680)	Data  0.007 ( 0.010)	Loss 6.7445e-02 (5.1786e-02)	Acc@1  98.05 ( 98.44)	Acc@5 100.00 (100.00)
Test Epoch: [166/200], lr: 0.000005, acc: 95.1875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [167][ 0/25]	Time  0.669 ( 0.669)	Data  0.006 ( 0.006)	Loss 5.6899e-02 (5.6899e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [167][12/25]	Time  0.659 ( 0.676)	Data  0.007 ( 0.006)	Loss 5.3215e-02 (5.0077e-02)	Acc@1  98.05 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [167][24/25]	Time  0.664 ( 0.673)	Data  0.006 ( 0.006)	Loss 7.5845e-02 (5.1806e-02)	Acc@1  96.48 ( 98.59)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [167/200], lr: 0.000005, acc: 95.5000, best: 96.3125
Epoch: [168][ 0/25]	Time  0.678 ( 0.678)	Data  0.006 ( 0.006)	Loss 3.5672e-02 (3.5672e-02)	Acc@1  99.61 ( 99.61)	Acc@5 100.00 (100.00)
Epoch: [168][12/25]	Time  0.663 ( 0.680)	Data  0.006 ( 0.006)	Loss 3.9554e-02 (5.0022e-02)	Acc@1  99.22 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [168][24/25]	Time  0.677 ( 0.682)	Data  0.006 ( 0.006)	Loss 3.9259e-02 (5.0819e-02)	Acc@1  99.61 ( 98.59)	Acc@5 100.00 (100.00)
Test Epoch: [168/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [169][ 0/25]	Time  0.668 ( 0.668)	Data  0.006 ( 0.006)	Loss 5.2959e-02 (5.2959e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [169][12/25]	Time  0.675 ( 0.670)	Data  0.007 ( 0.006)	Loss 6.0766e-02 (5.3858e-02)	Acc@1  98.05 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [169][24/25]	Time  0.675 ( 0.678)	Data  0.005 ( 0.006)	Loss 3.5222e-02 (5.1134e-02)	Acc@1  99.61 ( 98.55)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [169/200], lr: 0.000005, acc: 95.4375, best: 96.3125
Epoch: [170][ 0/25]	Time  0.673 ( 0.673)	Data  0.006 ( 0.006)	Loss 2.7109e-02 (2.7109e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [170][12/25]	Time  0.753 ( 0.675)	Data  0.006 ( 0.006)	Loss 3.6140e-02 (4.5787e-02)	Acc@1  98.83 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [170][24/25]	Time  0.672 ( 0.674)	Data  0.007 ( 0.006)	Loss 6.6535e-02 (5.2622e-02)	Acc@1  96.88 ( 98.56)	Acc@5 100.00 (100.00)
Test Epoch: [170/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [171][ 0/25]	Time  0.669 ( 0.669)	Data  0.006 ( 0.006)	Loss 7.6299e-02 (7.6299e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [171][12/25]	Time  0.667 ( 0.683)	Data  0.006 ( 0.006)	Loss 4.6152e-02 (5.1054e-02)	Acc@1  99.61 ( 98.56)	Acc@5 100.00 (100.00)
Epoch: [171][24/25]	Time  0.669 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.2882e-02 (5.2530e-02)	Acc@1  98.05 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [171/200], lr: 0.000005, acc: 95.0625, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [172][ 0/25]	Time  0.667 ( 0.667)	Data  0.007 ( 0.007)	Loss 4.4086e-02 (4.4086e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [172][12/25]	Time  0.675 ( 0.678)	Data  0.007 ( 0.007)	Loss 4.3169e-02 (5.1277e-02)	Acc@1  98.44 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [172][24/25]	Time  0.667 ( 0.677)	Data  0.006 ( 0.007)	Loss 5.6583e-02 (5.2789e-02)	Acc@1  97.27 ( 98.56)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [172/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [173][ 0/25]	Time  0.678 ( 0.678)	Data  0.007 ( 0.007)	Loss 5.1163e-02 (5.1163e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [173][12/25]	Time  0.663 ( 0.673)	Data  0.006 ( 0.006)	Loss 5.6211e-02 (5.8003e-02)	Acc@1  97.66 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [173][24/25]	Time  0.666 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.2239e-02 (5.2919e-02)	Acc@1  98.83 ( 98.36)	Acc@5 100.00 (100.00)
Test Epoch: [173/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [174][ 0/25]	Time  0.670 ( 0.670)	Data  0.007 ( 0.007)	Loss 4.6853e-02 (4.6853e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [174][12/25]	Time  0.685 ( 0.678)	Data  0.006 ( 0.006)	Loss 5.3623e-02 (5.4209e-02)	Acc@1  98.83 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [174][24/25]	Time  0.661 ( 0.678)	Data  0.006 ( 0.006)	Loss 5.3545e-02 (5.2876e-02)	Acc@1  98.05 ( 98.47)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [174/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [175][ 0/25]	Time  0.671 ( 0.671)	Data  0.006 ( 0.006)	Loss 4.8628e-02 (4.8628e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [175][12/25]	Time  0.679 ( 0.671)	Data  0.007 ( 0.006)	Loss 3.3638e-02 (5.6817e-02)	Acc@1  99.61 ( 98.14)	Acc@5 100.00 (100.00)
Epoch: [175][24/25]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 5.0032e-02 (5.4178e-02)	Acc@1  97.27 ( 98.23)	Acc@5 100.00 (100.00)
Test Epoch: [175/200], lr: 0.000005, acc: 95.3125, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [176][ 0/25]	Time  0.661 ( 0.661)	Data  0.006 ( 0.006)	Loss 5.3844e-02 (5.3844e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [176][12/25]	Time  0.666 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.3703e-02 (5.0876e-02)	Acc@1  99.22 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [176][24/25]	Time  0.670 ( 0.674)	Data  0.007 ( 0.006)	Loss 7.1424e-02 (5.3464e-02)	Acc@1  98.05 ( 98.58)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [176/200], lr: 0.000005, acc: 95.1250, best: 96.3125
Epoch: [177][ 0/25]	Time  0.688 ( 0.688)	Data  0.007 ( 0.007)	Loss 5.5345e-02 (5.5345e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [177][12/25]	Time  0.701 ( 0.694)	Data  0.006 ( 0.014)	Loss 7.9911e-02 (5.8979e-02)	Acc@1  97.66 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [177][24/25]	Time  0.668 ( 0.684)	Data  0.006 ( 0.010)	Loss 3.5033e-02 (5.3908e-02)	Acc@1  99.61 ( 98.44)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [177/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [178][ 0/25]	Time  0.665 ( 0.665)	Data  0.006 ( 0.006)	Loss 5.3872e-02 (5.3872e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [178][12/25]	Time  0.673 ( 0.668)	Data  0.006 ( 0.006)	Loss 5.5846e-02 (4.9582e-02)	Acc@1  98.05 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [178][24/25]	Time  0.666 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.0429e-02 (5.2428e-02)	Acc@1  98.05 ( 98.44)	Acc@5 100.00 (100.00)
Test Epoch: [178/200], lr: 0.000005, acc: 95.3750, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [179][ 0/25]	Time  0.660 ( 0.660)	Data  0.006 ( 0.006)	Loss 4.0193e-02 (4.0193e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [179][12/25]	Time  0.670 ( 0.666)	Data  0.006 ( 0.006)	Loss 4.8449e-02 (5.0902e-02)	Acc@1  99.22 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [179][24/25]	Time  0.665 ( 0.670)	Data  0.006 ( 0.006)	Loss 5.8906e-02 (5.1455e-02)	Acc@1  98.05 ( 98.56)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [179/200], lr: 0.000005, acc: 95.5000, best: 96.3125
Epoch: [180][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 3.6670e-02 (3.6670e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [180][12/25]	Time  0.663 ( 0.679)	Data  0.006 ( 0.006)	Loss 3.7920e-02 (5.3188e-02)	Acc@1  99.22 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [180][24/25]	Time  0.665 ( 0.674)	Data  0.006 ( 0.006)	Loss 7.0175e-02 (5.2060e-02)	Acc@1  98.05 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [180/200], lr: 0.000005, acc: 95.5625, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [181][ 0/25]	Time  0.661 ( 0.661)	Data  0.007 ( 0.007)	Loss 4.9721e-02 (4.9721e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [181][12/25]	Time  0.660 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.6636e-02 (5.0458e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 (100.00)
Epoch: [181][24/25]	Time  0.664 ( 0.675)	Data  0.006 ( 0.006)	Loss 4.4099e-02 (5.1069e-02)	Acc@1  98.83 ( 98.56)	Acc@5 100.00 (100.00)
Test Epoch: [181/200], lr: 0.000005, acc: 95.7500, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [182][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 4.5824e-02 (4.5824e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [182][12/25]	Time  0.663 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.2609e-02 (4.9937e-02)	Acc@1  98.05 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [182][24/25]	Time  0.669 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.9715e-02 (5.1463e-02)	Acc@1  97.66 ( 98.48)	Acc@5 100.00 (100.00)
Test Epoch: [182/200], lr: 0.000005, acc: 95.7500, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [183][ 0/25]	Time  0.659 ( 0.659)	Data  0.007 ( 0.007)	Loss 3.0828e-02 (3.0828e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [183][12/25]	Time  0.673 ( 0.679)	Data  0.008 ( 0.015)	Loss 6.3606e-02 (5.6801e-02)	Acc@1  97.66 ( 98.17)	Acc@5 100.00 (100.00)
Epoch: [183][24/25]	Time  0.674 ( 0.679)	Data  0.006 ( 0.011)	Loss 3.4759e-02 (5.1439e-02)	Acc@1  99.61 ( 98.53)	Acc@5 100.00 (100.00)
Test Epoch: [183/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [184][ 0/25]	Time  0.666 ( 0.666)	Data  0.007 ( 0.007)	Loss 5.9040e-02 (5.9040e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [184][12/25]	Time  0.672 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.1205e-02 (4.8676e-02)	Acc@1  99.22 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [184][24/25]	Time  0.668 ( 0.682)	Data  0.006 ( 0.006)	Loss 5.9672e-02 (5.1648e-02)	Acc@1  98.05 ( 98.53)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [184/200], lr: 0.000005, acc: 95.8750, best: 96.3125
Epoch: [185][ 0/25]	Time  0.687 ( 0.687)	Data  0.007 ( 0.007)	Loss 4.1517e-02 (4.1517e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [185][12/25]	Time  0.668 ( 0.677)	Data  0.006 ( 0.006)	Loss 4.9611e-02 (5.4840e-02)	Acc@1  99.22 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [185][24/25]	Time  0.669 ( 0.675)	Data  0.006 ( 0.006)	Loss 4.8617e-02 (5.2439e-02)	Acc@1  98.44 ( 98.47)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [185/200], lr: 0.000005, acc: 95.3125, best: 96.3125
Epoch: [186][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 3.8439e-02 (3.8439e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [186][12/25]	Time  0.671 ( 0.684)	Data  0.006 ( 0.006)	Loss 4.8060e-02 (4.8762e-02)	Acc@1  98.83 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [186][24/25]	Time  0.679 ( 0.677)	Data  0.006 ( 0.006)	Loss 6.4820e-02 (5.2592e-02)	Acc@1  97.66 ( 98.52)	Acc@5 100.00 (100.00)
Test Epoch: [186/200], lr: 0.000005, acc: 95.5000, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [187][ 0/25]	Time  0.680 ( 0.680)	Data  0.006 ( 0.006)	Loss 5.4402e-02 (5.4402e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [187][12/25]	Time  0.689 ( 0.676)	Data  0.006 ( 0.006)	Loss 3.4986e-02 (5.8342e-02)	Acc@1  99.22 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [187][24/25]	Time  0.795 ( 0.682)	Data  0.006 ( 0.006)	Loss 6.0293e-02 (5.5606e-02)	Acc@1  97.27 ( 98.33)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [187/200], lr: 0.000005, acc: 95.7500, best: 96.3125
Epoch: [188][ 0/25]	Time  0.675 ( 0.675)	Data  0.007 ( 0.007)	Loss 6.6358e-02 (6.6358e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [188][12/25]	Time  0.664 ( 0.672)	Data  0.007 ( 0.006)	Loss 4.0937e-02 (4.4422e-02)	Acc@1  98.83 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [188][24/25]	Time  0.674 ( 0.674)	Data  0.006 ( 0.006)	Loss 8.7192e-02 (5.3719e-02)	Acc@1  96.09 ( 98.20)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [188/200], lr: 0.000005, acc: 96.3125, best: 96.3125
Epoch: [189][ 0/25]	Time  0.669 ( 0.669)	Data  0.007 ( 0.007)	Loss 4.3748e-02 (4.3748e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [189][12/25]	Time  0.668 ( 0.675)	Data  0.006 ( 0.006)	Loss 7.4772e-02 (5.5345e-02)	Acc@1  97.66 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [189][24/25]	Time  0.675 ( 0.675)	Data  0.006 ( 0.006)	Loss 5.8354e-02 (5.3576e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Test Epoch: [189/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [190][ 0/25]	Time  0.666 ( 0.666)	Data  0.006 ( 0.006)	Loss 4.8134e-02 (4.8134e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [190][12/25]	Time  0.663 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.4947e-02 (4.8317e-02)	Acc@1  99.61 ( 98.80)	Acc@5 100.00 (100.00)
Epoch: [190][24/25]	Time  0.662 ( 0.674)	Data  0.006 ( 0.006)	Loss 4.9956e-02 (5.5719e-02)	Acc@1  97.66 ( 98.42)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [190/200], lr: 0.000005, acc: 95.7500, best: 96.3125
Epoch: [191][ 0/25]	Time  0.667 ( 0.667)	Data  0.006 ( 0.006)	Loss 5.0401e-02 (5.0401e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [191][12/25]	Time  0.672 ( 0.671)	Data  0.006 ( 0.006)	Loss 4.2435e-02 (5.3974e-02)	Acc@1  98.44 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [191][24/25]	Time  0.664 ( 0.668)	Data  0.007 ( 0.006)	Loss 3.3866e-02 (5.5110e-02)	Acc@1  99.22 ( 98.28)	Acc@5 100.00 (100.00)
Test Epoch: [191/200], lr: 0.000005, acc: 96.1250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [192][ 0/25]	Time  0.676 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.3136e-02 (4.3136e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [192][12/25]	Time  0.671 ( 0.677)	Data  0.006 ( 0.006)	Loss 6.0314e-02 (5.3484e-02)	Acc@1  98.05 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [192][24/25]	Time  0.671 ( 0.677)	Data  0.006 ( 0.006)	Loss 5.6987e-02 (5.4400e-02)	Acc@1  98.05 ( 98.22)	Acc@5 100.00 (100.00)
Test Epoch: [192/200], lr: 0.000005, acc: 96.1250, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [193][ 0/25]	Time  0.663 ( 0.663)	Data  0.007 ( 0.007)	Loss 5.6903e-02 (5.6903e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [193][12/25]	Time  0.663 ( 0.670)	Data  0.007 ( 0.006)	Loss 3.8227e-02 (5.5979e-02)	Acc@1  99.61 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [193][24/25]	Time  0.663 ( 0.673)	Data  0.007 ( 0.006)	Loss 6.3096e-02 (5.3100e-02)	Acc@1  97.66 ( 98.30)	Acc@5 100.00 (100.00)
Test Epoch: [193/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [194][ 0/25]	Time  0.668 ( 0.668)	Data  0.007 ( 0.007)	Loss 4.0274e-02 (4.0274e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [194][12/25]	Time  0.673 ( 0.685)	Data  0.006 ( 0.006)	Loss 4.6167e-02 (5.8265e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [194][24/25]	Time  0.670 ( 0.682)	Data  0.007 ( 0.006)	Loss 3.9312e-02 (5.3600e-02)	Acc@1  98.83 ( 98.42)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [194/200], lr: 0.000005, acc: 95.9375, best: 96.3125
Epoch: [195][ 0/25]	Time  0.670 ( 0.670)	Data  0.007 ( 0.007)	Loss 5.0623e-02 (5.0623e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [195][12/25]	Time  0.666 ( 0.674)	Data  0.006 ( 0.006)	Loss 5.6886e-02 (4.9858e-02)	Acc@1  98.05 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [195][24/25]	Time  0.668 ( 0.678)	Data  0.006 ( 0.006)	Loss 5.9107e-02 (5.3922e-02)	Acc@1  98.83 ( 98.25)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [195/200], lr: 0.000005, acc: 95.6875, best: 96.3125
Epoch: [196][ 0/25]	Time  0.700 ( 0.700)	Data  0.006 ( 0.006)	Loss 5.4386e-02 (5.4386e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [196][12/25]	Time  0.667 ( 0.675)	Data  0.005 ( 0.006)	Loss 4.9361e-02 (5.6550e-02)	Acc@1  98.83 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [196][24/25]	Time  0.667 ( 0.671)	Data  0.006 ( 0.006)	Loss 5.3158e-02 (5.3775e-02)	Acc@1  98.44 ( 98.33)	Acc@5 100.00 (100.00)
Test Epoch: [196/200], lr: 0.000005, acc: 95.6875, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Epoch: [197][ 0/25]	Time  0.660 ( 0.660)	Data  0.007 ( 0.007)	Loss 5.1670e-02 (5.1670e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [197][12/25]	Time  0.674 ( 0.676)	Data  0.006 ( 0.006)	Loss 5.1293e-02 (5.2188e-02)	Acc@1  99.61 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [197][24/25]	Time  0.662 ( 0.673)	Data  0.007 ( 0.006)	Loss 4.1658e-02 (5.4008e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [197/200], lr: 0.000005, acc: 95.9375, best: 96.3125
Epoch: [198][ 0/25]	Time  0.663 ( 0.663)	Data  0.006 ( 0.006)	Loss 5.9408e-02 (5.9408e-02)	Acc@1  98.05 ( 98.05)	Acc@5 100.00 (100.00)
Epoch: [198][12/25]	Time  0.671 ( 0.670)	Data  0.006 ( 0.006)	Loss 4.5623e-02 (4.8230e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [198][24/25]	Time  0.677 ( 0.680)	Data  0.006 ( 0.006)	Loss 4.8951e-02 (5.3231e-02)	Acc@1  98.44 ( 98.38)	Acc@5 100.00 (100.00)
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果
Test Epoch: [198/200], lr: 0.000005, acc: 95.9375, best: 96.3125
Epoch: [199][ 0/25]	Time  0.670 ( 0.670)	Data  0.006 ( 0.006)	Loss 4.4519e-02 (4.4519e-02)	Acc@1  98.83 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [199][12/25]	Time  0.668 ( 0.673)	Data  0.006 ( 0.006)	Loss 4.2649e-02 (4.9917e-02)	Acc@1  98.83 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [199][24/25]	Time  0.683 ( 0.676)	Data  0.006 ( 0.006)	Loss 4.8831e-02 (5.2763e-02)	Acc@1  98.83 ( 98.47)	Acc@5 100.00 (100.00)
Test Epoch: [199/200], lr: 0.000005, acc: 95.4375, best: 96.3125
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:291: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_res[str(epoch)] = [train_acc.cpu().item(), train_loss]  # 记录训练结果
D:\Files\Learning\University\DL\SNN\spikingjelly\TC-LIF-main\RDP_TCLIF\mn_train.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_res[str(epoch)] = [acc1.cpu().item()]  # 记录验证结果

Process finished with exit code 0
